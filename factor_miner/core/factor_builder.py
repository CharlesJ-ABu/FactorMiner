"""
ç»Ÿä¸€å› å­æ„å»ºå™¨ V3.0
æ•´åˆæ‰€æœ‰å› å­æ„å»ºåŠŸèƒ½ï¼Œä¸é€æ˜å› å­å­˜å‚¨ç³»ç»Ÿå®Œå…¨å…¼å®¹
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Union, Callable
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

from .factor_storage import TransparentFactorStorage
from .factor_engine import FactorEngine


class FactorBuilder:
    """
    ç»Ÿä¸€å› å­æ„å»ºå™¨ V3.0
    æ•´åˆæ‰€æœ‰ç±»å‹çš„å› å­æ„å»ºåŠŸèƒ½ï¼Œä¸é€æ˜å› å­å­˜å‚¨ç³»ç»Ÿå®Œå…¨å…¼å®¹
    """
    
    def __init__(self, config: Optional[Dict] = None):
        """
        åˆå§‹åŒ–å› å­æ„å»ºå™¨
        
        Args:
            config: é…ç½®å­—å…¸
        """
        self.config = config or {}
        self.storage = TransparentFactorStorage()
        self.engine = FactorEngine()
        
        # æ³¨å†Œæ‰€æœ‰å¯ç”¨çš„å› å­æ„å»ºæ–¹æ³•
        self.factor_builders = {
            'technical': self._build_technical_factors,
            'statistical': self._build_statistical_factors,
            'advanced': self._build_advanced_factors,
            'ml': self._build_ml_factors,
            'crypto': self._build_crypto_factors,
            'pattern': self._build_pattern_factors,
            'composite': self._build_composite_factors,
            'sentiment': self._build_sentiment_factors
        }
        
    def build_all_factors(self, data: pd.DataFrame, 
                         factor_types: Optional[List[str]] = None,
                         save_to_storage: bool = True,
                         progress_callback: Optional[callable] = None,
                         **kwargs) -> pd.DataFrame:
        """
        æ„å»ºæ‰€æœ‰ç±»å‹çš„å› å­
        
        Args:
            data: å¸‚åœºæ•°æ®
            factor_types: å› å­ç±»å‹åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™æ„å»ºæ‰€æœ‰ç±»å‹
            save_to_storage: æ˜¯å¦ä¿å­˜åˆ°V3å­˜å‚¨ç³»ç»Ÿ
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            å› å­DataFrame
        """
        if factor_types is None:
            factor_types = list(self.factor_builders.keys())
        
        all_factors = {}
        built_factors = {}
        
        print(f"ğŸš€ å¼€å§‹æ„å»ºå› å­ï¼Œç±»å‹: {', '.join(factor_types)}")
        
        for factor_type in factor_types:
            if factor_type in self.factor_builders:
                try:
                    print(f"ğŸ“Š æ„å»º {factor_type} ç±»å‹å› å­...")
                    factors = self.factor_builders[factor_type](data, **kwargs)
                    
                    if isinstance(factors, dict):
                        all_factors.update(factors)
                        built_factors[factor_type] = factors
                    elif isinstance(factors, pd.DataFrame):
                        for col in factors.columns:
                            all_factors[col] = factors[col]
                        built_factors[factor_type] = factors.to_dict('series')
                        
                    print(f"âœ… {factor_type} ç±»å‹å› å­æ„å»ºå®Œæˆï¼Œå…± {len(factors)} ä¸ª")
                    
                except Exception as e:
                    print(f"âŒ æ„å»º {factor_type} ç±»å‹å› å­å¤±è´¥: {e}")
                    continue
        
        # è½¬æ¢ä¸ºDataFrame
        factors_df = pd.DataFrame(all_factors, index=data.index)
        
        print(f"ğŸ‰ å› å­æ„å»ºå®Œæˆï¼Œæ€»å…± {len(factors_df.columns)} ä¸ªå› å­")
        
        # ä¿å­˜åˆ°V3å­˜å‚¨ç³»ç»Ÿ
        if save_to_storage:
            self._save_factors_to_storage(built_factors, data, **kwargs)
        
        return factors_df
    
    def _build_technical_factors(self, data: pd.DataFrame, **kwargs) -> Dict[str, pd.Series]:
        """æ„å»ºæŠ€æœ¯æŒ‡æ ‡å› å­"""
        factors = {}
        
        # ç§»åŠ¨å¹³å‡ç±»å› å­
        for period in [5, 10, 20, 50, 100]:
            # SMA
            factors[f'sma_{period}'] = data['close'].rolling(window=period).mean()
            
            # EMA
            factors[f'ema_{period}'] = data['close'].ewm(span=period).mean()
            
            # ä»·æ ¼ä½ç½®
            factors[f'price_position_sma_{period}'] = (data['close'] - factors[f'sma_{period}']) / factors[f'sma_{period}']
        
        # åŠ¨é‡ç±»å› å­
        for period in [14, 21]:
            # RSI
            delta = data['close'].diff()
            gain = delta.where(delta > 0, 0)
            loss = -delta.where(delta < 0, 0)
            avg_gain = gain.rolling(window=period).mean()
            avg_loss = loss.rolling(window=period).mean()
            rs = avg_gain / avg_loss
            factors[f'rsi_{period}'] = 100 - (100 / (1 + rs))
            
            # åŠ¨é‡
            factors[f'momentum_{period}'] = data['close'] / data['close'].shift(period) - 1
        
        # æ³¢åŠ¨ç‡ç±»å› å­
        for period in [20, 50]:
            # å†å²æ³¢åŠ¨ç‡
            returns = data['close'].pct_change()
            factors[f'volatility_{period}'] = returns.rolling(window=period).std() * np.sqrt(period)
            
            # ATR
            high_low = data['high'] - data['low']
            high_close = np.abs(data['high'] - data['close'].shift())
            low_close = np.abs(data['low'] - data['close'].shift())
            ranges = pd.concat([high_low, high_close, low_close], axis=1)
            true_range = ranges.max(axis=1)
            factors[f'atr_{period}'] = true_range.rolling(window=period).mean()
        
        # å¸ƒæ—å¸¦
        for period in [20, 50]:
            sma = data['close'].rolling(window=period).mean()
            std = data['close'].rolling(window=period).std()
            factors[f'bb_upper_{period}'] = sma + (std * 2)
            factors[f'bb_lower_{period}'] = sma - (std * 2)
            factors[f'bb_width_{period}'] = (factors[f'bb_upper_{period}'] - factors[f'bb_lower_{period}']) / sma
            factors[f'bb_position_{period}'] = (data['close'] - factors[f'bb_lower_{period}']) / (factors[f'bb_upper_{period}'] - factors[f'bb_lower_{period}'])
        
        # æˆäº¤é‡ç±»å› å­
        for period in [20, 50]:
            # æˆäº¤é‡SMA
            factors[f'volume_sma_{period}'] = data['volume'].rolling(window=period).mean()
            
            # æˆäº¤é‡æ¯”ç‡
            factors[f'volume_ratio_{period}'] = data['volume'] / factors[f'volume_sma_{period}']
            
            # OBV
            obv = pd.Series(index=data.index, dtype=float)
            obv.iloc[0] = data['volume'].iloc[0]
            for i in range(1, len(data)):
                if data['close'].iloc[i] > data['close'].iloc[i-1]:
                    obv.iloc[i] = obv.iloc[i-1] + data['volume'].iloc[i]
                elif data['close'].iloc[i] < data['close'].iloc[i-1]:
                    obv.iloc[i] = obv.iloc[i-1] - data['volume'].iloc[i]
                else:
                    obv.iloc[i] = obv.iloc[i-1]
            factors[f'obv_{period}'] = obv
            
            # VWAP
            typical_price = (data['high'] + data['low'] + data['close']) / 3
            vwap = (typical_price * data['volume']).rolling(window=period).sum() / data['volume'].rolling(window=period).sum()
            factors[f'vwap_{period}'] = vwap
        
        return factors
    
    def _build_statistical_factors(self, data: pd.DataFrame, **kwargs) -> Dict[str, pd.Series]:
        """æ„å»ºç»Ÿè®¡å› å­"""
        factors = {}
        
        # Z-scoreç±»å› å­
        for period in [20, 50, 100]:
            # ä»·æ ¼Z-score
            sma = data['close'].rolling(window=period).mean()
            std = data['close'].rolling(window=period).std()
            factors[f'price_zscore_{period}'] = (data['close'] - sma) / std
            
            # æ”¶ç›Šç‡Z-score
            returns = data['close'].pct_change()
            returns_sma = returns.rolling(window=period).mean()
            returns_std = returns.rolling(window=period).std()
            factors[f'returns_zscore_{period}'] = (returns - returns_sma) / returns_std
        
        # ç™¾åˆ†ä½æ’å
        for period in [20, 50]:
            factors[f'price_percentile_{period}'] = data['close'].rolling(window=period).rank(pct=True)
            factors[f'volume_percentile_{period}'] = data['volume'].rolling(window=period).rank(pct=True)
        
        # ç›¸å…³æ€§å› å­
        for period in [20, 50]:
            # ä»·æ ¼ä¸æˆäº¤é‡ç›¸å…³æ€§
            factors[f'price_volume_corr_{period}'] = data['close'].rolling(window=period).corr(data['volume'])
            
            # é«˜ä½ä»·ç›¸å…³æ€§
            factors[f'high_low_corr_{period}'] = data['high'].rolling(window=period).corr(data['low'])
        
        # ååº¦å’Œå³°åº¦
        for period in [20, 50]:
            returns = data['close'].pct_change()
            factors[f'returns_skew_{period}'] = returns.rolling(window=period).skew()
            factors[f'returns_kurt_{period}'] = returns.rolling(window=period).kurt()
        
        # åˆ†ä½æ•°å› å­
        for period in [20, 50]:
            for q in [0.1, 0.25, 0.75, 0.9]:
                factors[f'price_q{int(q*100)}_{period}'] = data['close'].rolling(window=period).quantile(q)
        
        return factors
    
    def _build_advanced_factors(self, data: pd.DataFrame, **kwargs) -> Dict[str, pd.Series]:
        """æ„å»ºé«˜çº§å› å­"""
        factors = {}
        
        # è¶‹åŠ¿å¼ºåº¦å› å­
        for period in [20, 50]:
            # ADX
            high_diff = data['high'].diff()
            low_diff = data['low'].diff()
            
            plus_dm = high_diff.where((high_diff > low_diff) & (high_diff > 0), 0)
            minus_dm = -low_diff.where((low_diff > high_diff) & (low_diff > 0), 0)
            
            tr = self._calculate_true_range(data)
            
            plus_di = 100 * (plus_dm.rolling(window=period).mean() / tr.rolling(window=period).mean())
            minus_di = 100 * (minus_dm.rolling(window=period).mean() / tr.rolling(window=period).mean())
            
            dx = 100 * abs(plus_di - minus_di) / (plus_di + minus_di)
            factors[f'adx_{period}'] = dx.rolling(window=period).mean()
        
        # ä»·æ ¼å½¢æ€å› å­
        for period in [5, 10, 20]:
            # ä»·æ ¼çªç ´
            high_max = data['high'].rolling(window=period).max()
            low_min = data['low'].rolling(window=period).min()
            
            factors[f'breakout_high_{period}'] = (data['close'] > high_max.shift(1)).astype(int)
            factors[f'breakout_low_{period}'] = (data['close'] < low_min.shift(1)).astype(int)
            
            # ä»·æ ¼é€šé“ä½ç½®
            factors[f'channel_position_{period}'] = (data['close'] - low_min) / (high_max - low_min)
        
        # æ”¯æ’‘é˜»åŠ›å› å­
        for period in [20, 50]:
            # æ”¯æ’‘ä½ï¼ˆå±€éƒ¨æœ€å°å€¼ï¼‰
            support = data['low'].rolling(window=period, center=True).min()
            factors[f'support_level_{period}'] = support
            
            # é˜»åŠ›ä½ï¼ˆå±€éƒ¨æœ€å¤§å€¼ï¼‰
            resistance = data['high'].rolling(window=period, center=True).max()
            factors[f'resistance_level_{period}'] = resistance
            
            # è·ç¦»æ”¯æ’‘é˜»åŠ›çš„æ¯”ä¾‹
            factors[f'distance_to_support_{period}'] = (data['close'] - support) / data['close']
            factors[f'distance_to_resistance_{period}'] = (resistance - data['close']) / data['close']
        
        # å¸‚åœºç»“æ„å› å­
        for period in [20, 50]:
            # é«˜ä½ç‚¹æ¯”ç‡
            high_ratio = data['high'] / data['high'].rolling(window=period).max()
            low_ratio = data['low'] / data['low'].rolling(window=period).min()
            factors[f'high_low_ratio_{period}'] = high_ratio / low_ratio
            
            # ä»·æ ¼æ•ˆç‡
            price_change = abs(data['close'] - data['close'].shift(period))
            path_length = data['close'].diff().abs().rolling(window=period).sum()
            factors[f'price_efficiency_{period}'] = price_change / path_length
        
        return factors
    
    def _build_ml_factors(self, data: pd.DataFrame, **kwargs) -> Dict[str, pd.Series]:
        """æ„å»ºæœºå™¨å­¦ä¹ å› å­"""
        factors = {}
        
        # è·å–è¿›åº¦å›è°ƒå‡½æ•°
        progress_callback = kwargs.get('progress_callback')
        
        try:
            from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
            from sklearn.linear_model import LinearRegression, Ridge
            from sklearn.preprocessing import StandardScaler
            from sklearn.decomposition import PCA
            from sklearn.feature_selection import SelectKBest, f_regression
            
            # æ­¥éª¤1: å‡†å¤‡ç‰¹å¾ (20%)
            if progress_callback:
                progress_callback('factor_building', 20, 'æ­£åœ¨å‡†å¤‡MLç‰¹å¾æ•°æ®...')
            
            features = self._prepare_ml_features(data)
            target = self._prepare_ml_target(data)
            
            # æ­¥éª¤2: æ•°æ®æ¸…ç† (30%)
            if progress_callback:
                progress_callback('factor_building', 30, 'æ­£åœ¨æ¸…ç†å’ŒéªŒè¯æ•°æ®...')
            
            # ç§»é™¤NaNå€¼
            valid_idx = ~(features.isna().any(axis=1) | target.isna())
            features_clean = features.loc[valid_idx]
            target_clean = target.loc[valid_idx]
            
            if len(features_clean) < 100:
                print("âš ï¸ æ•°æ®é‡ä¸è¶³ï¼Œæ— æ³•æ„å»ºMLå› å­")
                if progress_callback:
                    progress_callback('factor_building', 0, 'æ•°æ®é‡ä¸è¶³ï¼Œæ— æ³•æ„å»ºMLå› å­')
                return factors
            
            # æ­¥éª¤3: ç‰¹å¾æ ‡å‡†åŒ– (40%)
            if progress_callback:
                progress_callback('factor_building', 40, 'æ­£åœ¨æ ‡å‡†åŒ–ç‰¹å¾æ•°æ®...')
            
            # æ ‡å‡†åŒ–ç‰¹å¾
            scaler = StandardScaler()
            features_scaled = scaler.fit_transform(features_clean)
            
            # æ­¥éª¤4: æ„å»ºéšæœºæ£®æ—å› å­ (50%)
            if progress_callback:
                progress_callback('factor_building', 50, 'æ­£åœ¨è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹...')
            
            try:
                rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
                rf_model.fit(features_scaled, target_clean)
                rf_predictions = rf_model.predict(features_scaled)
                
                factor_series = pd.Series(index=data.index, dtype=float)
                factor_series.loc[valid_idx] = rf_predictions
                factors['ml_random_forest'] = factor_series
                print("âœ… éšæœºæ£®æ—å› å­æ„å»ºæˆåŠŸ")
            except Exception as e:
                print(f"âŒ éšæœºæ£®æ—å› å­æ„å»ºå¤±è´¥: {e}")
            
            # æ­¥éª¤5: æ„å»ºæ¢¯åº¦æå‡å› å­ (60%)
            if progress_callback:
                progress_callback('factor_building', 60, 'æ­£åœ¨è®­ç»ƒæ¢¯åº¦æå‡æ¨¡å‹...')
            
            try:
                gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)
                gb_model.fit(features_scaled, target_clean)
                gb_predictions = gb_model.predict(features_scaled)
                
                factor_series = pd.Series(index=data.index, dtype=float)
                factor_series.loc[valid_idx] = gb_predictions
                factors['ml_gradient_boosting'] = factor_series
                print("âœ… æ¢¯åº¦æå‡å› å­æ„å»ºæˆåŠŸ")
            except Exception as e:
                print(f"âŒ æ¢¯åº¦æå‡å› å­æ„å»ºå¤±è´¥: {e}")
            
            # æ­¥éª¤6: æ„å»ºPCAå› å­ (70%)
            if progress_callback:
                progress_callback('factor_building', 70, 'æ­£åœ¨è®¡ç®—PCAä¸»æˆåˆ†...')
            
            try:
                pca = PCA(n_components=3, random_state=42)
                pca_features = pca.fit_transform(features_scaled)
                
                for i in range(3):
                    factor_series = pd.Series(index=data.index, dtype=float)
                    factor_series.loc[valid_idx] = pca_features[:, i]
                    factors[f'ml_pca_component_{i+1}'] = factor_series
                print("âœ… PCAå› å­æ„å»ºæˆåŠŸ")
            except Exception as e:
                print(f"âŒ PCAå› å­æ„å»ºå¤±è´¥: {e}")
            
            # æ­¥éª¤7: æ„å»ºç‰¹å¾é€‰æ‹©å› å­ (80%)
            if progress_callback:
                progress_callback('factor_building', 80, 'æ­£åœ¨é€‰æ‹©æœ€ä¼˜ç‰¹å¾...')
            
            try:
                selector = SelectKBest(score_func=f_regression, k=5)
                selected_features = selector.fit_transform(features_scaled, target_clean)
                
                for i in range(5):
                    factor_series = pd.Series(index=data.index, dtype=float)
                    factor_series.loc[valid_idx] = selected_features[:, i]
                    factors[f'ml_selected_feature_{i+1}'] = factor_series
                print("âœ… ç‰¹å¾é€‰æ‹©å› å­æ„å»ºæˆåŠŸ")
            except Exception as e:
                print(f"âŒ ç‰¹å¾é€‰æ‹©å› å­æ„å»ºå¤±è´¥: {e}")
                
            # æ­¥éª¤8: MLå› å­æ„å»ºå®Œæˆ (90%)
            if progress_callback:
                progress_callback('factor_building', 90, 'MLå› å­æ„å»ºå®Œæˆï¼Œæ­£åœ¨æ•´ç†ç»“æœ...')
            
            print(f"ğŸ‰ MLå› å­æ„å»ºå®Œæˆï¼Œå…±ç”Ÿæˆ {len(factors)} ä¸ªå› å­")
            
        except ImportError:
            print("âš ï¸ sklearnæœªå®‰è£…ï¼Œè·³è¿‡MLå› å­æ„å»º")
            if progress_callback:
                progress_callback('factor_building', 0, 'sklearnæœªå®‰è£…ï¼Œè·³è¿‡MLå› å­æ„å»º')
        
        return factors
    
    def _clean_ml_features(self, features: pd.DataFrame) -> pd.DataFrame:
        """æ¸…ç†MLç‰¹å¾æ•°æ®ï¼Œå¤„ç†æ— ç©·å¤§å€¼å’Œå¼‚å¸¸å€¼"""
        try:
            # å¤åˆ¶ç‰¹å¾æ•°æ®
            cleaned_features = features.copy()
            
            # å¤„ç†æ— ç©·å¤§å€¼
            cleaned_features = cleaned_features.replace([np.inf, -np.inf], np.nan)
            
            # å¤„ç†å¼‚å¸¸å¤§çš„å€¼ï¼ˆè¶…è¿‡3ä¸ªæ ‡å‡†å·®ï¼‰
            for col in cleaned_features.columns:
                if cleaned_features[col].dtype in ['float64', 'float32']:
                    # è®¡ç®—æœ‰æ•ˆå€¼çš„ç»Ÿè®¡ä¿¡æ¯
                    valid_data = cleaned_features[col].dropna()
                    if len(valid_data) > 0:
                        mean_val = valid_data.mean()
                        std_val = valid_data.std()
                        
                        if std_val > 0:
                            # å°†è¶…è¿‡3ä¸ªæ ‡å‡†å·®çš„å€¼è®¾ä¸ºNaN
                            upper_bound = mean_val + 3 * std_val
                            lower_bound = mean_val - 3 * std_val
                            cleaned_features[col] = cleaned_features[col].clip(lower_bound, upper_bound)
            
            # ç”¨å‰å‘å¡«å……å’Œåå‘å¡«å……å¤„ç†NaNå€¼
            cleaned_features = cleaned_features.fillna(method='ffill').fillna(method='bfill')
            
            # å¦‚æœè¿˜æœ‰NaNå€¼ï¼Œç”¨0å¡«å……
            cleaned_features = cleaned_features.fillna(0)
            
            print(f"âœ… MLç‰¹å¾æ¸…ç†å®Œæˆï¼Œå¤„ç†äº† {features.isna().sum().sum()} ä¸ªNaNå€¼")
            return cleaned_features
            
        except Exception as e:
            print(f"âŒ MLç‰¹å¾æ¸…ç†å¤±è´¥: {e}")
            # å¦‚æœæ¸…ç†å¤±è´¥ï¼Œè¿”å›åŸå§‹ç‰¹å¾
            return features
    
    def _build_crypto_factors(self, data: pd.DataFrame, **kwargs) -> Dict[str, pd.Series]:
        """æ„å»ºåŠ å¯†è´§å¸ç‰¹æœ‰å› å­"""
        factors = {}
        
        # èµ„é‡‘è´¹ç‡ç›¸å…³å› å­ï¼ˆå¦‚æœæœ‰æ•°æ®ï¼‰
        if 'funding_rate' in data.columns:
            for period in [8, 24, 72]:
                factors[f'funding_rate_ma_{period}'] = data['funding_rate'].rolling(window=period).mean()
                factors[f'funding_rate_std_{period}'] = data['funding_rate'].rolling(window=period).std()
        
        # æ°¸ç»­æº¢ä»·å› å­
        if 'mark_price' in data.columns and 'index_price' in data.columns:
            factors['perpetual_premium'] = (data['mark_price'] - data['index_price']) / data['index_price']
        
        # ç½‘ç»œä»·å€¼å› å­ï¼ˆæ¨¡æ‹Ÿï¼‰
        for period in [24, 72, 168]:
            # æ¨¡æ‹Ÿç½‘ç»œæ´»è·ƒåº¦
            volume_ma = data['volume'].rolling(window=period).mean()
            price_ma = data['close'].rolling(window=period).mean()
            factors[f'network_value_{period}'] = volume_ma * price_ma
        
        # æ³¢åŠ¨ç‡è°ƒæ•´æ”¶ç›Š
        for period in [24, 72]:
            returns = data['close'].pct_change()
            volatility = returns.rolling(window=period).std()
            factors[f'volatility_adjusted_return_{period}'] = returns / volatility
        
        return factors
    
    def _build_pattern_factors(self, data: pd.DataFrame, **kwargs) -> Dict[str, pd.Series]:
        """æ„å»ºä»·æ ¼å½¢æ€å› å­"""
        factors = {}
        
        # èœ¡çƒ›å›¾å½¢æ€
        for period in [1, 3, 5]:
            # é”¤å­çº¿
            body_size = abs(data['close'] - data['open'])
            lower_shadow = data['open'].where(data['close'] > data['open'], data['close']) - data['low']
            upper_shadow = data['high'] - data['open'].where(data['close'] > data['open'], data['close'])
            
            hammer_condition = (lower_shadow > 2 * body_size) & (upper_shadow < body_size)
            factors[f'hammer_pattern_{period}'] = hammer_condition.rolling(window=period).sum()
            
            # åå­—æ˜Ÿ
            doji_condition = (body_size < 0.1 * (data['high'] - data['low']))
            factors[f'doji_pattern_{period}'] = doji_condition.rolling(window=period).sum()
        
        # ç¼ºå£å› å­
        for period in [1, 3, 5]:
            # å‘ä¸Šç¼ºå£
            gap_up = (data['low'] > data['high'].shift(1))
            factors[f'gap_up_{period}'] = gap_up.rolling(window=period).sum()
            
            # å‘ä¸‹ç¼ºå£
            gap_down = (data['high'] < data['low'].shift(1))
            factors[f'gap_down_{period}'] = gap_down.rolling(window=period).sum()
        
        # è¶‹åŠ¿çº¿å› å­
        for period in [20, 50]:
            # ä¸Šå‡è¶‹åŠ¿çº¿
            highs = data['high'].rolling(window=period, center=True).max()
            factors[f'uptrend_line_{period}'] = (data['close'] > highs * 0.98).astype(int)
            
            # ä¸‹é™è¶‹åŠ¿çº¿
            lows = data['low'].rolling(window=period, center=True).min()
            factors[f'downtrend_line_{period}'] = (data['close'] < lows * 1.02).astype(int)
        
        return factors
    
    def _build_composite_factors(self, data: pd.DataFrame, **kwargs) -> Dict[str, pd.Series]:
        """æ„å»ºå¤åˆå› å­"""
        factors = {}
        
        # å¤šå› å­ç»„åˆ
        for period in [20, 50]:
            # è¶‹åŠ¿åŠ¨é‡ç»„åˆ
            sma_20 = data['close'].rolling(window=20).mean()
            sma_50 = data['close'].rolling(window=50).mean()
            trend = (sma_20 > sma_50).astype(int)
            
            rsi = self._calculate_rsi(data['close'], period)
            momentum = (rsi > 50).astype(int)
            
            factors[f'trend_momentum_{period}'] = trend * momentum
            
            # æ³¢åŠ¨ç‡è°ƒæ•´åŠ¨é‡
            returns = data['close'].pct_change()
            volatility = returns.rolling(window=period).std()
            momentum_vol_adj = returns / volatility
            factors[f'momentum_vol_adj_{period}'] = momentum_vol_adj.rolling(window=period).mean()
        
        # å¸‚åœºæƒ…ç»ªå› å­
        for period in [20, 50]:
            # ä»·æ ¼æˆäº¤é‡ä¸€è‡´æ€§
            price_up = (data['close'] > data['close'].shift(1)).astype(int)
            volume_up = (data['volume'] > data['volume'].shift(1)).astype(int)
            consistency = (price_up == volume_up).astype(int)
            factors[f'price_volume_consistency_{period}'] = consistency.rolling(window=period).mean()
        
        return factors
    
    def _build_sentiment_factors(self, data: pd.DataFrame, **kwargs) -> Dict[str, pd.Series]:
        """æ„å»ºæƒ…ç»ªå› å­"""
        factors = {}
        
        # ææ…Œè´ªå©ªæŒ‡æ•°ï¼ˆæ¨¡æ‹Ÿï¼‰
        for period in [24, 72, 168]:
            # åŸºäºä»·æ ¼å’Œæˆäº¤é‡çš„æƒ…ç»ªæŒ‡æ ‡
            returns = data['close'].pct_change()
            volatility = returns.rolling(window=period).std()
            volume_ratio = data['volume'] / data['volume'].rolling(window=period).mean()
            
            # ææ…ŒæŒ‡æ•°ï¼šé«˜æ³¢åŠ¨ç‡ + é«˜æˆäº¤é‡
            fear_index = (volatility * volume_ratio).rolling(window=period).mean()
            factors[f'fear_index_{period}'] = fear_index
            
            # è´ªå©ªæŒ‡æ•°ï¼šä½æ³¢åŠ¨ç‡ + ç¨³å®šä¸Šæ¶¨
            greed_condition = (volatility < volatility.rolling(window=period).quantile(0.3)) & (returns > 0)
            factors[f'greed_index_{period}'] = greed_condition.rolling(window=period).mean()
        
        # å¸‚åœºç»“æ„æƒ…ç»ª
        for period in [20, 50]:
            # æ–°é«˜æ–°ä½æ¯”ç‡
            new_highs = (data['close'] > data['close'].rolling(window=period).max().shift(1)).astype(int)
            new_lows = (data['close'] < data['close'].rolling(window=period).min().shift(1)).astype(int)
            
            factors[f'new_highs_ratio_{period}'] = new_highs.rolling(window=period).mean()
            factors[f'new_lows_ratio_{period}'] = new_lows.rolling(window=period).mean()
            factors[f'high_low_ratio_{period}'] = factors[f'new_highs_ratio_{period}'] / (factors[f'new_lows_ratio_{period}'] + 1e-8)
        
        return factors
    
    def _prepare_ml_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """å‡†å¤‡æœºå™¨å­¦ä¹ ç‰¹å¾"""
        features = pd.DataFrame(index=data.index)
        
        try:
            # ä»·æ ¼ç‰¹å¾
            features['price'] = data['close']
            features['price_change'] = data['close'].pct_change()
            features['price_change_2'] = data['close'].pct_change(2)
            features['price_change_5'] = data['close'].pct_change(5)
            
            # æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾
            features['sma_20'] = data['close'].rolling(window=20).mean()
            features['sma_50'] = data['close'].rolling(window=50).mean()
            features['rsi_14'] = self._calculate_rsi(data['close'], 14)
            
            # æˆäº¤é‡ç‰¹å¾
            features['volume'] = data['volume']
            features['volume_change'] = data['volume'].pct_change()
            features['volume_ma'] = data['volume'].rolling(window=20).mean()
            
            # æ³¢åŠ¨ç‡ç‰¹å¾
            returns = data['close'].pct_change()
            features['volatility'] = returns.rolling(window=20).std()
            
            # æ•°æ®æ¸…ç†ï¼šå¤„ç†æ— ç©·å¤§å€¼å’Œå¼‚å¸¸å€¼
            features = self._clean_ml_features(features)
            
            return features
            
        except Exception as e:
            print(f"âŒ å‡†å¤‡MLç‰¹å¾å¤±è´¥: {e}")
            # è¿”å›ç©ºçš„ç‰¹å¾DataFrame
            return pd.DataFrame(index=data.index)
    
    def _prepare_ml_target(self, data: pd.DataFrame) -> pd.Series:
        """å‡†å¤‡æœºå™¨å­¦ä¹ ç›®æ ‡å˜é‡"""
        # ä½¿ç”¨æœªæ¥1æœŸçš„æ”¶ç›Šç‡ä½œä¸ºç›®æ ‡
        return data['close'].pct_change().shift(-1)
    
    def _calculate_rsi(self, prices: pd.Series, period: int) -> pd.Series:
        """è®¡ç®—RSIæŒ‡æ ‡"""
        delta = prices.diff()
        gain = delta.where(delta > 0, 0)
        loss = -delta.where(delta < 0, 0)
        
        avg_gain = gain.rolling(window=period).mean()
        avg_loss = loss.rolling(window=period).mean()
        
        rs = avg_gain / avg_loss
        rsi = 100 - (100 / (1 + rs))
        
        return rsi
    
    def _calculate_true_range(self, data: pd.DataFrame) -> pd.Series:
        """è®¡ç®—çœŸå®æ³¢å¹…"""
        high_low = data['high'] - data['low']
        high_close = np.abs(data['high'] - data['close'].shift())
        low_close = np.abs(data['low'] - data['close'].shift())
        
        ranges = pd.concat([high_low, high_close, low_close], axis=1)
        true_range = ranges.max(axis=1)
        
        return true_range
    
    def _save_factors_to_storage(self, built_factors: Dict, data: pd.DataFrame, **kwargs):
        """å°†æ„å»ºçš„å› å­ä¿å­˜åˆ°V3å­˜å‚¨ç³»ç»Ÿ"""
        print("ğŸ’¾ å¼€å§‹ä¿å­˜å› å­åˆ°V3å­˜å‚¨ç³»ç»Ÿ...")
        
        for factor_type, factors in built_factors.items():
            for factor_name, factor_series in factors.items():
                try:
                    # åˆ›å»ºå› å­å®šä¹‰ - ç§»é™¤V3åç¼€
                    factor_id = factor_name
                    
                    # æ ¹æ®å› å­ç±»å‹é€‰æ‹©ä¿å­˜æ–¹æ³•
                    if factor_type == 'ml':
                        # MLå› å­ï¼šæ™ºèƒ½æ£€æµ‹artifactè·¯å¾„ï¼Œä¼˜å…ˆä¿å­˜ä¸ºml_modelç±»å‹
                        models_dir = Path(__file__).parent.parent.parent / "factorlib" / "models"
                        artifact_file = models_dir / f"{factor_id}.pkl"
                        
                        # æ£€æŸ¥å¤šä¸ªå¯èƒ½çš„è·¯å¾„ï¼Œç¡®ä¿èƒ½æ‰¾åˆ°artifact
                        artifact_found = False
                        artifact_paths = [
                            artifact_file,
                            models_dir / f"{factor_id}.pkl",
                            Path.cwd() / "factorlib" / "models" / f"{factor_id}.pkl",
                            Path(__file__).parent.parent.parent / "factorlib" / "models" / f"{factor_id}.pkl"
                        ]
                        
                        for path in artifact_paths:
                            if path.exists():
                                artifact_file = path
                                artifact_found = True
                                print(f"âœ… æ‰¾åˆ°MLå› å­artifact: {path}")
                                break
                        
                        if artifact_found:
                            # ä¿å­˜ä¸ºml_modelç±»å‹
                            success = self.storage.save_ml_model_factor(
                                factor_id=factor_id,
                                name=factor_name,
                                artifact_filename=artifact_file.name,
                                description=f"æœºå™¨å­¦ä¹ ç”Ÿæˆçš„{factor_name}å› å­",
                                category=factor_type,
                                parameters={}
                            )
                            if success:
                                print(f"âœ… MLå› å­ {factor_name} ä¿å­˜ä¸ºml_modelç±»å‹æˆåŠŸ")
                        else:
                            print(f"âš ï¸ æœªæ‰¾åˆ°MLå› å­artifact: {factor_id}.pklï¼Œå°è¯•ä¿å­˜ä¸ºfunctionç±»å‹")
                            # å³ä½¿æ²¡æœ‰artifactï¼ŒMLå› å­ä¹Ÿåº”è¯¥ä¿å­˜ä¸ºfunctionç±»å‹
                            # å› ä¸ºå®ƒä»¬çš„è®¡ç®—é€»è¾‘åœ¨functionsæ–‡ä»¶ä¸­
                        success = self.storage.save_function_factor(
                            factor_id=factor_id,
                            name=factor_name,
                            function_code=self._generate_ml_factor_code(factor_name, factor_type),
                                description=f"æœºå™¨å­¦ä¹ ç”Ÿæˆçš„{factor_name}å› å­ï¼ˆå‡½æ•°å®ç°ï¼‰",
                            category=factor_type,
                            parameters={}
                        )
                        if success:
                            print(f"âœ… MLå› å­ {factor_name} ä¿å­˜ä¸ºfunctionç±»å‹æˆåŠŸ")
                    else:
                        # å…¶ä»–å› å­ä¿å­˜ä¸ºå…¬å¼ç±»å‹
                        success = self.storage.save_formula_factor(
                            factor_id=factor_id,
                            name=factor_name,
                            formula=self._generate_factor_formula(factor_name, factor_type),
                            description=f"è‡ªåŠ¨ç”Ÿæˆçš„{factor_name}å› å­",
                            category=factor_type,
                            parameters=self._extract_factor_parameters(factor_name)
                        )
                    
                    if success:
                        print(f"âœ… å› å­ {factor_name} ä¿å­˜æˆåŠŸ")
                    else:
                        print(f"âŒ å› å­ {factor_name} ä¿å­˜å¤±è´¥")
                        
                except Exception as e:
                    print(f"âŒ ä¿å­˜å› å­ {factor_name} æ—¶å‡ºé”™: {e}")
                    continue
        
        print("ğŸ’¾ å› å­ä¿å­˜å®Œæˆ")
    
    def _generate_ml_factor_code(self, factor_name: str, factor_type: str) -> str:
        """ç”ŸæˆMLå› å­çš„Pythonä»£ç """
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºPCAå› å­
        is_pca_factor = factor_name.startswith('pca_component_')
        
        if is_pca_factor:
            return self._generate_pca_factor_code(factor_name, factor_type)
        else:
            return self._generate_standard_ml_factor_code(factor_name, factor_type)
    
    def _generate_pca_factor_code(self, factor_name: str, factor_type: str) -> str:
        """ç”ŸæˆPCAå› å­çš„Pythonä»£ç """
        # ä»å› å­åä¸­æå–ç»„ä»¶ç´¢å¼•
        component_index = int(factor_name.split('_')[-1]) - 1  # pca_component_3 -> 2
        
        return f"""
import pandas as pd
import numpy as np
import pickle
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

def calculate(data: pd.DataFrame, **kwargs) -> pd.Series:
    \"\"\"
    è®¡ç®—{factor_name}å› å­
    
    æ™ºèƒ½åŠ è½½é¢„è®­ç»ƒçš„PCAæ¨¡å‹ï¼Œä½¿ç”¨pklæ–‡ä»¶è¿›è¡Œé™ç»´
    
    Args:
        data: å¸‚åœºæ•°æ®DataFrameï¼Œå¿…é¡»åŒ…å« OHLCV åˆ—
        **kwargs: å…¶ä»–å‚æ•°
        
        Returns:
        å› å­å€¼Seriesï¼Œç¬¬{component_index + 1}ä¸ªä¸»æˆåˆ†
    \"\"\"
    try:
        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        required_cols = ['open', 'high', 'low', 'close', 'volume']
        if data is None or len(data) == 0:
            return pd.Series(dtype=float)
        
        missing_cols = [col for col in required_cols if col not in data.columns]
        if missing_cols:
            print(f"ç¼ºå°‘å¿…è¦çš„åˆ—: {{missing_cols}}")
            return pd.Series(index=data.index, dtype=float)
        
        # æ™ºèƒ½æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
        model_paths = [
            Path(__file__).parent.parent / "models" / "{factor_name}.pkl",
            Path.cwd() / "factorlib" / "models" / "{factor_name}.pkl",
            Path(__file__).parent.parent.parent / "models" / "{factor_name}.pkl"
        ]
        
        artifact_file = None
        for path in model_paths:
            if path.exists():
                artifact_file = path
                break
        
        if artifact_file is None:
            print(f"æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {{factor_name}}.pkl")
            print(f"å°è¯•è¿‡çš„è·¯å¾„: {{[str(p) for p in model_paths]}}")
            return pd.Series(index=data.index, dtype=float)
        
        # åŠ è½½é¢„è®­ç»ƒçš„æ¨¡å‹
        with open(artifact_file, 'rb') as f:
            artifact = pickle.load(f)
        
        model = artifact.get("model")
        feature_columns = artifact.get("feature_columns", [])
        scaler = artifact.get("scaler")
        
        if model is None:
            print("æ¨¡å‹æ–‡ä»¶æŸåï¼šæ— æ³•åŠ è½½æ¨¡å‹")
            return pd.Series(index=data.index, dtype=float)
        
        # æ„å»ºç‰¹å¾ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
        features = _build_features(data)
        
        # å¯¹é½æ‰€éœ€åˆ—
        missing = [c for c in feature_columns if c not in features.columns]
        if missing:
            print(f"ç¼ºå°‘ç‰¹å¾åˆ—: {{missing}}")
            # å¯¹ç¼ºå¤±åˆ—è¡¥NaNï¼Œä¿æŒåˆ—é½å…¨
            for c in missing:
                features[c] = np.nan
        
        X = features[feature_columns]
        
        # æ¸…æ´—ä¸æ ‡å‡†åŒ– - PCAä¸æ¥å—NaNå€¼
        X = X.replace([np.inf, -np.inf], np.nan)
        
        # å¤„ç†NaNå€¼ - PCAä¸æ¥å—NaNå€¼
        # æ–¹æ³•1ï¼šå‰å‘å¡«å……ï¼Œç„¶ååå‘å¡«å……
        X_cleaned = X.fillna(method='ffill').fillna(method='bfill')
        
        # æ–¹æ³•2ï¼šå¦‚æœä»æœ‰NaNå€¼ï¼Œç”¨0å¡«å……
        if X_cleaned.isna().any().any():
            print(f"è­¦å‘Šï¼šä»æœ‰NaNå€¼ï¼Œç”¨0å¡«å……")
            X_cleaned = X_cleaned.fillna(0)
        
        # æ–¹æ³•3ï¼šå¦‚æœæŸè¡Œå…¨æ˜¯NaNï¼Œåˆ é™¤è¯¥è¡Œ
        valid_rows = ~X_cleaned.isna().all(axis=1)
        if not valid_rows.all():
            print(f"åˆ é™¤åŒ…å«å…¨NaNçš„è¡Œï¼Œä»{{len(X_cleaned)}}è¡Œå‡å°‘åˆ°{{valid_rows.sum()}}è¡Œ")
            X_cleaned = X_cleaned[valid_rows]
            # åŒæ—¶æ›´æ–°ç´¢å¼•
            data = data.loc[valid_rows]
        
        if scaler is not None:
            X_scaled = scaler.transform(X_cleaned)
        else:
            X_scaled = X_cleaned.values
        
        # PCAè½¬æ¢ï¼ˆé™ç»´ï¼‰
        # PCAä¸æ˜¯é¢„æµ‹æ¨¡å‹ï¼Œè€Œæ˜¯é™ç»´å·¥å…·ï¼Œä½¿ç”¨transformæ–¹æ³•
        try:
            X_transformed = model.transform(X_scaled)
            
            # å–ç¬¬{component_index + 1}ä¸ªä¸»æˆåˆ†ï¼ˆç´¢å¼•ä¸º{component_index}ï¼‰
            # å¦‚æœn_components < {component_index + 1}ï¼Œåˆ™å–æœ€åä¸€ä¸ª
            component_index_actual = min({component_index}, model.n_components_ - 1)
            y_pred = X_transformed[:, component_index_actual]
            
        except Exception as e:
            print(f"PCAè½¬æ¢å¤±è´¥: {{e}}")
            # å¦‚æœPCAè½¬æ¢å¤±è´¥ï¼Œè¿”å›NaNåºåˆ—
            return pd.Series(index=data.index, dtype=float)
        
        return pd.Series(y_pred, index=data.index)
        
    except Exception as e:
        print(f"è®¡ç®—{factor_name}å› å­æ—¶å‡ºé”™: {{e}}")
        import traceback
        traceback.print_exc()
    return pd.Series(index=data.index, dtype=float)

def _build_features(data: pd.DataFrame) -> pd.DataFrame:
    \"\"\"æ„å»ºä¸è®­ç»ƒä¸€è‡´çš„ç‰¹å¾\"\"\"
    features = pd.DataFrame(index=data.index)
    
    # ä»·æ ¼åŠ¨é‡ç‰¹å¾
    features['price_momentum_1'] = data['close'].pct_change(1)
    features['price_momentum_5'] = data['close'].pct_change(5)
    features['price_momentum_10'] = data['close'].pct_change(10)
    
    # æˆäº¤é‡ç‰¹å¾
    features['volume_ratio'] = data['volume'] / data['volume'].rolling(20).mean()
    features['volume_momentum'] = data['volume'].pct_change(5)
    
    # æ³¢åŠ¨ç‡ç‰¹å¾
    features['volatility_10'] = data['close'].rolling(10).std() / data['close'].rolling(10).mean()
    features['volatility_20'] = data['close'].rolling(20).std() / data['close'].rolling(20).mean()
    
    # è¶‹åŠ¿ç‰¹å¾
    features['trend_5'] = (data['close'] - data['close'].shift(5)) / data['close'].shift(5)
    features['trend_10'] = (data['close'] - data['close'].shift(10)) / data['close'].shift(10)
    
    # ä»·æ ¼ä½ç½®ç‰¹å¾
    features['price_position_20'] = (data['close'] - data['low'].rolling(20).min()) / (data['high'].rolling(20).max() - data['low'].rolling(20).min())
    
    # ç§»åŠ¨å¹³å‡ç‰¹å¾
    features['ma_5'] = data['close'] / data['close'].rolling(5).mean() - 1
    features['ma_10'] = data['close'] / data['close'].rolling(10).mean() - 1
    features['ma_20'] = data['close'] / data['close'].rolling(20).mean() - 1
    
    return features
"""

    def _generate_standard_ml_factor_code(self, factor_name: str, factor_type: str) -> str:
        """ç”Ÿæˆæ ‡å‡†MLå› å­çš„Pythonä»£ç """
        return f"""
import pandas as pd
import numpy as np
import pickle
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

def calculate(data: pd.DataFrame, **kwargs) -> pd.Series:
    \"\"\"
    è®¡ç®—{factor_name}å› å­
    
    æ™ºèƒ½åŠ è½½é¢„è®­ç»ƒçš„MLæ¨¡å‹ï¼Œä½¿ç”¨pklæ–‡ä»¶è¿›è¡Œæ¨ç†
    
    Args:
        data: å¸‚åœºæ•°æ®DataFrameï¼Œå¿…é¡»åŒ…å« OHLCV åˆ—
        **kwargs: å…¶ä»–å‚æ•°
        
        Returns:
        å› å­å€¼Seriesï¼Œé¢„æµ‹ç»“æœ
    \"\"\"
    try:
        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        required_cols = ['open', 'high', 'low', 'close', 'volume']
        if data is None or len(data) == 0:
            return pd.Series(dtype=float)
        
        missing_cols = [col for col in required_cols if col not in data.columns]
        if missing_cols:
            print(f"ç¼ºå°‘å¿…è¦çš„åˆ—: {{missing_cols}}")
            return pd.Series(index=data.index, dtype=float)
        
        # æ™ºèƒ½æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
        model_paths = [
            Path(__file__).parent.parent / "models" / "{factor_name}.pkl",
            Path.cwd() / "factorlib" / "models" / "{factor_name}.pkl",
            Path(__file__).parent.parent.parent / "models" / "{factor_name}.pkl"
        ]
        
        artifact_file = None
        for path in model_paths:
            if path.exists():
                artifact_file = path
                break
        
        if artifact_file is None:
            print(f"æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {{factor_name}}.pkl")
            print(f"å°è¯•è¿‡çš„è·¯å¾„: {{[str(p) for p in model_paths]}}")
            return pd.Series(index=data.index, dtype=float)
        
        # åŠ è½½é¢„è®­ç»ƒçš„æ¨¡å‹
        with open(artifact_file, 'rb') as f:
            artifact = pickle.load(f)
        
        model = artifact.get("model")
        feature_columns = artifact.get("feature_columns", [])
        scaler = artifact.get("scaler")
        
        if model is None:
            print("æ¨¡å‹æ–‡ä»¶æŸåï¼šæ— æ³•åŠ è½½æ¨¡å‹")
            return pd.Series(index=data.index, dtype=float)
        
        # æ„å»ºç‰¹å¾ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
        features = _build_features(data)
        
        # å¯¹é½æ‰€éœ€åˆ—
        missing = [c for c in feature_columns if c not in features.columns]
        if missing:
            print(f"ç¼ºå°‘ç‰¹å¾åˆ—: {{missing}}")
            # å¯¹ç¼ºå¤±åˆ—è¡¥NaNï¼Œä¿æŒåˆ—é½å…¨
            for c in missing:
                features[c] = np.nan
        
        X = features[feature_columns]
        
        # æ¸…æ´—ä¸æ ‡å‡†åŒ–
        X = X.replace([np.inf, -np.inf], np.nan)
        X = X.fillna(method='ffill').fillna(method='bfill')
        
        if scaler is not None:
            X_scaled = scaler.transform(X)
        else:
            X_scaled = X.values
        
        # é¢„æµ‹
        y_pred = model.predict(X_scaled)
        return pd.Series(y_pred, index=data.index)
        
    except Exception as e:
        print(f"è®¡ç®—{factor_name}å› å­æ—¶å‡ºé”™: {{e}}")
        import traceback
        traceback.print_exc()
    return pd.Series(index=data.index, dtype=float)

def _build_features(data: pd.DataFrame) -> pd.DataFrame:
    \"\"\"æ„å»ºä¸è®­ç»ƒä¸€è‡´çš„ç‰¹å¾\"\"\"
    features = pd.DataFrame(index=data.index)
    
    # ä»·æ ¼åŠ¨é‡ç‰¹å¾
    features['price_momentum_1'] = data['close'].pct_change(1)
    features['price_momentum_5'] = data['close'].pct_change(5)
    features['price_momentum_10'] = data['close'].pct_change(10)
    
    # æˆäº¤é‡ç‰¹å¾
    features['volume_ratio'] = data['volume'] / data['volume'].rolling(20).mean()
    features['volume_momentum'] = data['volume'].pct_change(5)
    
    # æ³¢åŠ¨ç‡ç‰¹å¾
    features['volatility_10'] = data['close'].rolling(10).std() / data['close'].rolling(10).mean()
    features['volatility_20'] = data['close'].rolling(20).std() / data['close'].rolling(20).mean()
    
    # è¶‹åŠ¿ç‰¹å¾
    features['trend_5'] = (data['close'] - data['close'].shift(5)) / data['close'].shift(5)
    features['trend_10'] = (data['close'] - data['close'].shift(10)) / data['close'].shift(10)
    
    # ä»·æ ¼ä½ç½®ç‰¹å¾
    features['price_position_20'] = (data['close'] - data['low'].rolling(20).min()) / (data['high'].rolling(20).max() - data['low'].rolling(20).min())
    
    # ç§»åŠ¨å¹³å‡ç‰¹å¾
    features['ma_5'] = data['close'] / data['close'].rolling(5).mean() - 1
    features['ma_10'] = data['close'] / data['close'].rolling(10).mean() - 1
    features['ma_20'] = data['close'] / data['close'].rolling(20).mean() - 1
    
    return features
"""
    
    def _generate_factor_formula(self, factor_name: str, factor_type: str) -> str:
        """ç”Ÿæˆå› å­çš„å…¬å¼æè¿°"""
        return f"# {factor_name} å› å­çš„è®¡ç®—å…¬å¼\n# ç±»å‹: {factor_type}\n# è‡ªåŠ¨ç”Ÿæˆäº {pd.Timestamp.now()}"
    
    def _extract_factor_parameters(self, factor_name: str) -> Dict:
        """æå–å› å­å‚æ•°"""
        # ä»å› å­åç§°ä¸­æå–å‚æ•°
        params = {}
        
        if 'sma_' in factor_name:
            period = factor_name.split('_')[-1]
            params['period'] = int(period)
        elif 'rsi_' in factor_name:
            period = factor_name.split('_')[-1]
            params['period'] = int(period)
        elif 'bb_' in factor_name:
            period = factor_name.split('_')[-1]
            params['period'] = int(period)
            params['std_dev'] = 2
        
        return params
    
    def get_available_factors(self) -> Dict[str, List[str]]:
        """è·å–æ‰€æœ‰å¯ç”¨å› å­çš„ä¿¡æ¯"""
        return {
            'technical': ['sma', 'ema', 'rsi', 'macd', 'bollinger_bands', 'atr', 'obv', 'vwap'],
            'statistical': ['zscore', 'percentile', 'correlation', 'skewness', 'kurtosis'],
            'advanced': ['adx', 'trend_strength', 'support_resistance', 'market_structure'],
            'ml': ['random_forest', 'gradient_boosting', 'pca', 'feature_selection'],
            'crypto': ['funding_rate', 'perpetual_premium', 'network_value'],
            'pattern': ['candlestick_patterns', 'gaps', 'trendlines'],
            'composite': ['trend_momentum', 'volatility_adjusted', 'market_sentiment'],
            'sentiment': ['fear_greed', 'market_structure_sentiment']
        }
    
    def build_custom_factor(self, data: pd.DataFrame, factor_name: str, 
                          factor_func: Callable, **kwargs) -> pd.Series:
        """
        æ„å»ºè‡ªå®šä¹‰å› å­
        
        Args:
            data: å¸‚åœºæ•°æ®
            factor_name: å› å­åç§°
            factor_func: å› å­è®¡ç®—å‡½æ•°
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            è‡ªå®šä¹‰å› å­Series
        """
        try:
            factor = factor_func(data, **kwargs)
            if isinstance(factor, pd.Series):
                factor.name = factor_name
                return factor
            else:
                raise ValueError("å› å­å‡½æ•°å¿…é¡»è¿”å›pandas.Series")
        except Exception as e:
            print(f"æ„å»ºè‡ªå®šä¹‰å› å­ {factor_name} å¤±è´¥: {e}")
            return pd.Series(dtype=float) 