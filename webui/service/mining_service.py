# webui/services/mining_service.py
import sys

import pandas as pd
import numpy as np
from datetime import datetime
import json
from pathlib import Path
import uuid
import threading
import time
import psutil
import gc
from typing import Dict, Any, Optional, List


# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from factor_miner.api.factor_mining_api import FactorMiningAPI
from factor_miner.factors.ml_factors import MLFactorBuilder
from factor_miner.factors.technical import FactorCalculator
from factor_miner.factors.statistical import StatisticalFactorBuilder
from factor_miner.factors.advanced import AdvancedFactorBuilder

class MiningService:
    def __init__(self):
        # å…¨å±€æŒ–æ˜ä¼šè¯ç®¡ç†ï¼ˆå®é™…é¡¹ç›®ä¸­å»ºè®®ç”¨æ•°æ®åº“ï¼‰
        self.mining_sessions: Dict[str, Dict] = {}
        self.mining_progress: Dict[str, Dict] = {}

        # è¿›åº¦ä¼°ç®—é…ç½®
        self.PROGRESS_ESTIMATES = {
            'data_loading': {
                'base_time': 5,  # åŸºç¡€æ—¶é—´ï¼ˆç§’ï¼‰
                'time_per_gb': 2,  # æ¯GBæ•°æ®é¢å¤–æ—¶é—´
                'max_progress_steps': 10
            },
            'factor_building': {
                'base_time': 25,  # åŸºç¡€æ—¶é—´ï¼ˆç§’ï¼‰
                'time_per_factor_type': 12,  # æ¯ç§å› å­ç±»å‹é¢å¤–æ—¶é—´
                'time_per_symbol': 5,  # æ¯ä¸ªäº¤æ˜“å¯¹é¢å¤–æ—¶é—´
                'time_per_ml_algorithm': 25,  # æ¯ä¸ªMLç®—æ³•é¢å¤–æ—¶é—´
                'time_per_technical_factor': 8,  # æ¯ä¸ªæŠ€æœ¯å› å­é¢å¤–æ—¶é—´
                'time_per_statistical_factor': 10,  # æ¯ä¸ªç»Ÿè®¡å› å­é¢å¤–æ—¶é—´
                'time_per_advanced_factor': 15,  # æ¯ä¸ªé«˜çº§å› å­é¢å¤–æ—¶é—´
                'max_progress_steps': 35
            },
            'factor_evaluation': {
                'base_time': 25,  # åŸºç¡€æ—¶é—´ï¼ˆç§’ï¼‰
                'time_per_factor': 0.8,  # æ¯ä¸ªå› å­é¢å¤–æ—¶é—´
                'time_per_symbol': 5,  # æ¯ä¸ªäº¤æ˜“å¯¹é¢å¤–æ—¶é—´
                'max_progress_steps': 30
            },
            'factor_optimization': {
                'base_time': 15,  # åŸºç¡€æ—¶é—´ï¼ˆç§’ï¼‰
                'time_per_factor': 0.5,  # æ¯ä¸ªå› å­é¢å¤–æ—¶é—´
                'max_progress_steps': 20
            },
            'result_saving': {
                'base_time': 5,  # åŸºç¡€æ—¶é—´ï¼ˆç§’ï¼‰
                'max_progress_steps': 8
            }
        }

        # å› å­æ„å»ºå™¨å®ä¾‹ï¼ˆæ‡’åŠ è½½ï¼‰
        self._mining_api = None
        self._ml_factor_builder = None
        self._technical_factor_builder = None
        self._statistical_factor_builder = None
        self._advanced_factor_builder = None

    # --- å·¥å…·æ–¹æ³• ---
    def get_mining_api(self) -> FactorMiningAPI:
        if self._mining_api is None:
            self._mining_api = FactorMiningAPI()
        return self._mining_api

    def get_ml_factor_builder(self) -> MLFactorBuilder:
        if self._ml_factor_builder is None:
            self._ml_factor_builder = MLFactorBuilder()
        return self._ml_factor_builder

    def get_technical_factor_builder(self) -> FactorCalculator:
        if self._technical_factor_builder is None:
            self._technical_factor_builder = FactorCalculator()
        return self._technical_factor_builder

    def get_statistical_factor_builder(self) -> StatisticalFactorBuilder:
        if self._statistical_factor_builder is None:
            self._statistical_factor_builder = StatisticalFactorBuilder()
        return self._statistical_factor_builder

    def get_advanced_factor_builder(self) -> AdvancedFactorBuilder:
        if self._advanced_factor_builder is None:
            self._advanced_factor_builder = AdvancedFactorBuilder()
        return self._advanced_factor_builder

    def estimate_step_time(self, step_name: str, config: Dict, data_info: Optional[Dict] = None) -> tuple:
        """ä¼°ç®—æ­¥éª¤æ‰§è¡Œæ—¶é—´ï¼ˆåŒåŸå‡½æ•°é€»è¾‘ï¼‰"""
        # ... å®ç°ç»†èŠ‚åŒåŸ estimate_step_time å‡½æ•° ...
        if step_name not in self.PROGRESS_ESTIMATES:
            return 10, 10  # é»˜è®¤æ—¶é—´å’Œè¿›åº¦æ­¥æ•°

        estimates = self.PROGRESS_ESTIMATES[step_name]
        base_time = estimates['base_time']
        max_steps = estimates['max_progress_steps']

        # æ ¹æ®é…ç½®è°ƒæ•´æ—¶é—´
        if step_name == 'data_loading':
            # æ•°æ®åŠ è½½æ—¶é—´åŸºäºæ•°æ®å¤§å°
            if data_info and 'data_size_mb' in data_info:
                data_size_gb = data_info['data_size_mb'] / 1024
                estimated_time = base_time + (data_size_gb * estimates['time_per_gb'])
            else:
                estimated_time = base_time + 5  # é»˜è®¤é¢å¤–5ç§’
            progress_steps = min(max_steps, int(estimated_time / 2))

        elif step_name == 'factor_building':
            # å› å­æ„å»ºæ—¶é—´åŸºäºå› å­ç±»å‹å’Œäº¤æ˜“å¯¹æ•°é‡
            factor_types = config.get('factor_types', [])
            symbols = len(config.get('symbols', []))

            # ä¸åŒç±»å‹å› å­çš„æ—¶é—´ä¼°ç®—
            total_factor_time = 0
            for factor_type in factor_types:
                if factor_type == 'ml':
                    total_factor_time += estimates['time_per_ml_algorithm']
                elif factor_type == 'technical':
                    total_factor_time += estimates['time_per_technical_factor']
                elif factor_type == 'statistical':
                    total_factor_time += estimates['time_per_statistical_factor']
                elif factor_type == 'advanced':
                    total_factor_time += estimates['time_per_advanced_factor']
                else:
                    total_factor_time += estimates['time_per_factor_type']

            estimated_time = base_time + total_factor_time + (symbols * estimates['time_per_symbol'])
            progress_steps = min(max_steps, int(estimated_time / 3))

        elif step_name == 'factor_evaluation':
            # å› å­è¯„ä¼°æ—¶é—´åŸºäºå› å­æ•°é‡å’Œäº¤æ˜“å¯¹æ•°é‡
            factor_types = config.get('factor_types', [])
            symbols = len(config.get('symbols', []))

            # ä¸åŒç±»å‹å› å­ç”Ÿæˆçš„æ•°é‡ä¼°ç®—
            estimated_factors = 0
            for factor_type in factor_types:
                if factor_type == 'ml':
                    estimated_factors += 35  # MLç±»å‹ç”Ÿæˆæ›´å¤šå› å­
                elif factor_type == 'technical':
                    estimated_factors += 25  # æŠ€æœ¯å› å­æ•°é‡
                elif factor_type == 'statistical':
                    estimated_factors += 30  # ç»Ÿè®¡å› å­æ•°é‡
                elif factor_type == 'advanced':
                    estimated_factors += 20  # é«˜çº§å› å­æ•°é‡
                else:
                    estimated_factors += 20

            estimated_time = (base_time +
                              estimated_factors * estimates['time_per_factor'] +
                              symbols * estimates['time_per_symbol'])
            progress_steps = min(max_steps, int(estimated_time / 4))

        elif step_name == 'factor_optimization':
            # å› å­ä¼˜åŒ–æ—¶é—´åŸºäºå› å­æ•°é‡
            factor_types = config.get('factor_types', [])
            estimated_factors = 0
            for factor_type in factor_types:
                if factor_type == 'ml':
                    estimated_factors += 35
                elif factor_type == 'technical':
                    estimated_factors += 25
                elif factor_type == 'statistical':
                    estimated_factors += 30
                elif factor_type == 'advanced':
                    estimated_factors += 20
                else:
                    estimated_factors += 20

            estimated_time = base_time + estimated_factors * estimates['time_per_factor']
            progress_steps = min(max_steps, int(estimated_time / 2))

        else:  # result_saving
            estimated_time = base_time
            progress_steps = max_steps

        return max(estimated_time, 1), progress_steps

    def get_system_info(self) -> Dict:
        """è·å–ç³»ç»Ÿä¿¡æ¯ï¼ˆåŒåŸå‡½æ•°é€»è¾‘ï¼‰"""
        # ... å®ç°ç»†èŠ‚åŒåŸ get_system_info å‡½æ•° ...
        try:
            cpu_count = psutil.cpu_count()
            memory = psutil.virtual_memory()
            memory_gb = memory.total / (1024 ** 3)

            return {
                'cpu_count': cpu_count,
                'memory_gb': round(memory_gb, 1),
                'memory_percent': memory.percent
            }
        except:
            return {
                'cpu_count': 4,
                'memory_gb': 8.0,
                'memory_percent': 50
            }

    # --- æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ ---
    def start_mining(self, params: Dict) -> Dict:
        """å¯åŠ¨å› å­æŒ–æ˜ï¼ˆåŸ start_mining è·¯ç”±çš„æ ¸å¿ƒé€»è¾‘ï¼‰"""
        try:
            # å‚æ•°éªŒè¯
            required_fields = ['symbols', 'timeframes', 'factor_types', 'start_date', 'end_date']
            for field in required_fields:
                if field not in params:
                    return {'success': False, 'error': f'ç¼ºå°‘å¿…è¦å‚æ•°: {field}'}

            # åˆ›å»ºæŒ–æ˜ä¼šè¯
            session_id = str(uuid.uuid4())
            system_info = self.get_system_info()
            progress_info = self._init_progress_info(params)
            total_estimated_time = self._calculate_total_estimated_time(progress_info)

            # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
            self.mining_sessions[session_id] = {
                'status': 'pending',
                'start_time': datetime.now().isoformat(),
                'config': params,
                'progress': {k: 0 for k in progress_info.keys()},
                'progress_info': progress_info,
                'total_estimated_time': total_estimated_time,
                'current_step': 'data_loading',
                'messages': [],
                'system_info': system_info
            }

            # æ„å»ºæŒ–æ˜é…ç½®
            mining_config = self._build_mining_config(params)
            self._run_mining_background(session_id, params, mining_config)
            # å¯åŠ¨åå°æŒ–æ˜çº¿ç¨‹
            # thread = threading.Thread(
            #     target=self._run_mining_background,
            #     args=(session_id, params, mining_config)
            # )
            # thread.daemon = True
            # thread.start()

            return {
                'success': True,
                'session_id': self.mining_sessions,
                'message': 'å› å­æŒ–æ˜å·²å¯åŠ¨ï¼Œè¯·ä½¿ç”¨session_idæŸ¥è¯¢è¿›åº¦',
                'estimated_time': total_estimated_time,
                'system_info': system_info
            }

        except Exception as e:
            return {'success': False, 'error': f'å¯åŠ¨æŒ–æ˜å¤±è´¥: {str(e)}'}

    def _init_progress_info(self, params: Dict) -> Dict:
        """åˆå§‹åŒ–è¿›åº¦ä¿¡æ¯ï¼ˆåŒåŸå‡½æ•°é€»è¾‘ï¼‰"""
        progress_info = {}
        for step_name in ['data_loading', 'factor_building', 'factor_evaluation', 'factor_optimization', 'result_saving']:
            estimated_time, progress_steps = self.estimate_step_time(step_name, params)
            progress_info[step_name] = {
                'estimated_time': estimated_time,
                'progress_steps': progress_steps,
                'current_progress': 0,
                'start_time': None,
                'current_step_start': None
            }
        return progress_info

    def _calculate_total_estimated_time(self, progress_info: Dict) -> int:
        """è®¡ç®—æ€»é¢„ä¼°æ—¶é—´ï¼ˆåŒåŸå‡½æ•°é€»è¾‘ï¼‰"""
        return sum(step['estimated_time'] for step in progress_info.values())

    def _build_mining_config(self, params: Dict) -> Dict:
        """æ„å»ºæŒ–æ˜é…ç½®ï¼ˆåŒåŸå‡½æ•°é€»è¾‘ï¼‰"""
        return {
            'factor_types': params['factor_types'],
            'optimization': {
                'method': params.get('optimization_method', 'greedy'),
                'max_factors': params.get('max_factors', 15),
                'min_ic': params.get('min_ic', 0.02),
                'min_ir': params.get('min_ir', 0.1)
            },
            'evaluation': {
                'min_sample_size': params.get('min_sample_size', 30),
                'metrics': ['ic_pearson', 'ic_spearman', 'sharpe_ratio', 'win_rate', 'factor_decay']
            }
        }

    def _run_mining_background(self, session_id: str, params: Dict, mining_config: Dict):
        """åå°æ‰§è¡ŒæŒ–æ˜æµç¨‹ï¼ˆåŒåŸ run_mining_background å‡½æ•°é€»è¾‘ï¼‰"""
        try:
            api = self.get_mining_api()
            self.mining_sessions[session_id]['status'] = 'running'
            self.mining_sessions[session_id]['current_step'] = 'data_loading'

            # æ­¥éª¤1: æ•°æ®åŠ è½½
            data_result = self._execute_data_loading(session_id, params, api)

            # æ­¥éª¤2: å› å­æ„å»º
            self._execute_factor_building(session_id, params, api, data_result, mining_config)
            # æ›´æ–°ä¼šè¯çŠ¶æ€ä¸ºå®Œæˆ
            self.mining_sessions[session_id]['status'] = 'completed'
            self.mining_sessions[session_id]['end_time'] = datetime.now().isoformat()

        except Exception as e:
            self.mining_sessions[session_id]['status'] = 'error'
            self.mining_sessions[session_id]['error'] = str(e)
            self.mining_sessions[session_id]['end_time'] = datetime.now().isoformat()

    def _execute_data_loading(self, session_id: str, params: Dict, api: FactorMiningAPI):
        """æ‰§è¡Œæ•°æ®åŠ è½½ï¼ˆåŒåŸæ­¥éª¤1é€»è¾‘ï¼‰"""
        # ... å®ç°ç»†èŠ‚åŒåŸ run_mining_background ä¸­çš„ data_loading æ­¥éª¤ ...
        step_start_time = time.time()
        self.mining_sessions[session_id]['progress_info']['data_loading']['start_time'] = step_start_time
        self.mining_sessions[session_id]['progress_info']['data_loading']['current_step_start'] = step_start_time

        self.update_session_progress(session_id, 'data_loading', 0, 'å¼€å§‹åŠ è½½å¸‚åœºæ•°æ®...')

        # è·å–æ•°æ®å¤§å°ä¿¡æ¯
        data_info = self.get_data_info(params['symbols'][0], params['timeframes'][0], params['start_date'], params['end_date'])

        data_result = api.load_data(
            params['symbols'][0],
            params['timeframes'][0],
            params['start_date'],
            params['end_date']
        )

        if not data_result['success']:
            raise Exception(f"æ•°æ®åŠ è½½å¤±è´¥: {data_result['error']}")

        # æ›´æ–°æ•°æ®ä¿¡æ¯
        if 'data_info' not in self.mining_sessions[session_id]:
            self.mining_sessions[session_id]['data_info'] = {}
        self.mining_sessions[session_id]['data_info'].update(data_info)

        self.update_session_progress(session_id, 'data_loading', 100, 'æ•°æ®åŠ è½½å®Œæˆ')
        return data_result

    def _execute_factor_building(self, session_id: str, params: Dict, api: FactorMiningAPI, data_result=None,
                                 mining_config=None):
        """æ‰§è¡Œå› å­æ„å»ºï¼ˆåŒåŸæ­¥éª¤2é€»è¾‘ï¼‰"""
        # ... å®ç°ç»†èŠ‚åŒåŸ run_mining_background ä¸­çš„ factor_building æ­¥éª¤ ...
        step_start_time = time.time()
        self.mining_sessions[session_id]['progress_info']['factor_building']['start_time'] = step_start_time
        self.mining_sessions[session_id]['progress_info']['factor_building']['current_step_start'] = step_start_time
        # åˆå§‹åŒ–å­è¿›åº¦å®¹å™¨ï¼Œç¡®ä¿å‰ç«¯å¯è§
        self.mining_sessions[session_id]['progress_info'].setdefault('sub_progress', {})
        self.mining_sessions[session_id]['progress_info'].setdefault('sub_messages', {})
        self.mining_sessions[session_id]['progress_info']['sub_progress'].setdefault('ml', 0)

        self.update_session_progress(session_id, 'factor_building', 0, 'å¼€å§‹æ„å»ºå› å­...')

        # æ ¹æ®é€‰æ‹©çš„å› å­ç±»å‹æ„å»ºçœŸå®å› å­
        factor_types = params.get('factor_types', [])
        total_types = len(factor_types)

        # å› å­ç±»å‹æ˜¾ç¤ºåç§°æ˜ å°„
        factor_type_names = {
            'technical': 'æŠ€æœ¯å› å­',
            'statistical': 'ç»Ÿè®¡å› å­',
            'advanced': 'é«˜çº§å› å­',
            'ml': 'æœºå™¨å­¦ä¹ å› å­',
            'crypto': 'åŠ å¯†å› å­',
            'pattern': 'å½¢æ€å› å­',
            'composite': 'å¤åˆå› å­',
            'sentiment': 'æƒ…æ„Ÿå› å­'
        }

        # æ„å»ºå› å­
        all_factors = pd.DataFrame(index=data_result['data'].index)

        for i, factor_type in enumerate(factor_types):
            progress_percent = int((i / total_types) * 80) + 10  # 10% - 90%
            factor_type_name = factor_type_names.get(factor_type, factor_type)
            try:
                if factor_type == 'ml':
                    # ä½¿ç”¨çœŸå®çš„MLå› å­æ„å»ºç®—æ³•
                    self.update_session_progress(session_id, 'factor_building', progress_percent, f'æ­£åœ¨æ„å»ºæœºå™¨å­¦ä¹ å› å­...')

                    ml_builder = self.get_ml_factor_builder()

                    # å¼€å§‹MLå› å­æ„å»º

                    # æ‰§è¡ŒMLå› å­æ„å»ºï¼Œå¸¦è¿›åº¦æ›´æ–°
                    try:
                        # å¼€å§‹æ„å»ºé›†æˆå­¦ä¹ å› å­
                        self.update_session_progress(session_id, 'factor_building', progress_percent + 5,
                                                'æ­£åœ¨æ„å»ºé›†æˆå­¦ä¹ å› å­...')
                        print(f"å¼€å§‹æ„å»ºé›†æˆå­¦ä¹ å› å­...")

                        # å®šä¹‰æ™®é€šæŒ–æ˜çš„MLè¿›åº¦å›è°ƒ
                        def ml_progress_callback_normal(stage: str, progress: int, message: str = ""):
                            try:
                                pi = self.mining_sessions[session_id].setdefault('progress_info', {})
                                sp = pi.setdefault('sub_progress', {})
                                sm = pi.setdefault('sub_messages', {})
                                sp[stage] = int(progress)
                                print(f"ğŸ¯ æ™®é€šæŒ–æ˜MLè¿›åº¦: {stage} -> {progress}%")
                                if message:
                                    sm[stage] = message
                                # ä¸æ›´æ–°ä¸»è¿›åº¦ï¼Œåªæ›´æ–°å­è¿›åº¦ï¼Œé¿å…ä¸»è¿›åº¦æ¡"ç¼©æ”¾"æ•ˆæœ
                            except Exception as e:
                                print(f"âŒ æ™®é€šæŒ–æ˜MLè¿›åº¦å›è°ƒé”™è¯¯: {e}")

                        # è®©tqdmæ­£å¸¸å·¥ä½œï¼Œæ˜¾ç¤ºçœŸå®è¿›åº¦
                        ensemble_factors = ml_builder.build_ensemble_factors(
                            data_result['data'],
                            progress_callback=ml_progress_callback_normal,
                            window=252,
                            n_estimators=100
                        )
                        print(f"é›†æˆå­¦ä¹ å› å­æ„å»ºå®Œæˆ: {len(ensemble_factors.columns)} ä¸ª")

                        # æ„å»ºPCAå› å­
                        self.update_session_progress(session_id, 'factor_building', progress_percent + 10,
                                                'æ­£åœ¨æ„å»ºPCAå› å­...')
                        print(f"å¼€å§‹æ„å»ºPCAå› å­...")
                        pca_factors = ml_builder.build_pca_factors(
                            data_result['data'],
                            progress_callback=ml_progress_callback_normal,
                            n_components=10
                        )
                        print(f"PCAå› å­æ„å»ºå®Œæˆ: {len(pca_factors.columns)} ä¸ª")

                        # æ„å»ºç‰¹å¾é€‰æ‹©å› å­
                        self.update_session_progress(session_id, 'factor_building', progress_percent + 15,
                                                'æ­£åœ¨æ„å»ºç‰¹å¾é€‰æ‹©å› å­...')
                        print(f"å¼€å§‹æ„å»ºç‰¹å¾é€‰æ‹©å› å­...")
                        feature_factors = ml_builder.build_feature_selection_factors(
                            data_result['data'],
                            progress_callback=ml_progress_callback_normal,
                            k_best=20
                        )
                        print(f"ç‰¹å¾é€‰æ‹©å› å­æ„å»ºå®Œæˆ: {len(feature_factors.columns)} ä¸ª")

                        # æ„å»ºæ»šåŠ¨MLå› å­
                        self.update_session_progress(session_id, 'factor_building', progress_percent + 18,
                                                'æ­£åœ¨æ„å»ºæ»šåŠ¨MLå› å­...')
                        print(f"å¼€å§‹æ„å»ºæ»šåŠ¨MLå› å­...")
                        rolling_factors = ml_builder.build_rolling_ml_factors(
                            data_result['data'],
                            progress_callback=ml_progress_callback_normal,
                            window=252,
                            rolling_window=60
                        )
                        print(f"æ»šåŠ¨MLå› å­æ„å»ºå®Œæˆ: {len(rolling_factors.columns)} ä¸ª")

                        # æ„å»ºè‡ªé€‚åº”MLå› å­
                        self.update_session_progress(session_id, 'factor_building', progress_percent + 20,
                                                'æ­£åœ¨æ„å»ºè‡ªé€‚åº”MLå› å­...')
                        print(f"å¼€å§‹æ„å»ºè‡ªé€‚åº”MLå› å­...")
                        adaptive_factors = ml_builder.build_adaptive_ml_factors(
                            data_result['data'],
                            progress_callback=ml_progress_callback_normal,
                            threshold=0.1
                        )
                        print(f"è‡ªé€‚åº”MLå› å­æ„å»ºå®Œæˆ: {len(adaptive_factors.columns)} ä¸ª")

                        # åˆå¹¶æ‰€æœ‰MLå› å­
                        ml_factors_list = []
                        if not ensemble_factors.empty:
                            ml_factors_list.append(ensemble_factors)
                        if not pca_factors.empty:
                            ml_factors_list.append(pca_factors)
                        if not feature_factors.empty:
                            ml_factors_list.append(feature_factors)
                        if not rolling_factors.empty:
                            ml_factors_list.append(rolling_factors)
                        if not adaptive_factors.empty:
                            ml_factors_list.append(adaptive_factors)

                        if ml_factors_list:
                            ml_factors = pd.concat(ml_factors_list, axis=1)
                            all_factors = pd.concat([all_factors, ml_factors], axis=1)
                            print(f"âœ“ æˆåŠŸæ„å»ºMLå› å­: {len(ml_factors.columns)} ä¸ª")
                            self.update_session_progress(session_id, 'factor_building', progress_percent + 20,
                                                    f'æœºå™¨å­¦ä¹ å› å­æ„å»ºå®Œæˆ: {len(ml_factors.columns)} ä¸ª')
                        else:
                            print("âœ— MLå› å­æ„å»ºå®Œæˆï¼Œä½†ç»“æœä¸ºç©º")
                            self.update_session_progress(session_id, 'factor_building', progress_percent + 20,
                                                    'æœºå™¨å­¦ä¹ å› å­æ„å»ºå®Œæˆï¼Œä½†ç»“æœä¸ºç©º')

                    except Exception as ml_error:
                        print(f"âœ— MLå› å­æ„å»ºå¤±è´¥: {ml_error}")
                        self.update_session_progress(session_id, 'factor_building', progress_percent + 20,
                                                f'æœºå™¨å­¦ä¹ å› å­æ„å»ºå¤±è´¥: {str(ml_error)[:50]}...')

                elif factor_type == 'technical':
                    # æ„å»ºæŠ€æœ¯å› å­
                    self.update_session_progress(session_id, 'factor_building', progress_percent, f'æ­£åœ¨æ„å»ºæŠ€æœ¯å› å­...')

                    technical_builder = self.get_technical_factor_builder()

                    try:
                        # å…¼å®¹ä¸¤ç§æ¥å£ï¼šä¼˜å…ˆ calculate_all_factorsï¼Œå…¶æ¬¡ build_all_factors
                        if hasattr(technical_builder, 'calculate_all_factors'):
                            technical_factors = technical_builder.calculate_all_factors(data_result['data'])
                        else:
                            technical_factors = technical_builder.build_all_factors(data_result['data'])

                        if not technical_factors.empty:
                            all_factors = pd.concat([all_factors, technical_factors], axis=1)
                            print(f"âœ“ æˆåŠŸæ„å»ºæŠ€æœ¯å› å­: {len(technical_factors.columns)} ä¸ª")
                            self.update_session_progress(session_id, 'factor_building', progress_percent + 20,
                                                    f'æŠ€æœ¯å› å­æ„å»ºå®Œæˆ: {len(technical_factors.columns)} ä¸ª')
                        else:
                            print("âœ— æŠ€æœ¯å› å­æ„å»ºå®Œæˆï¼Œä½†ç»“æœä¸ºç©º")
                            self.update_session_progress(session_id, 'factor_building', progress_percent + 20,
                                                    'æŠ€æœ¯å› å­æ„å»ºå®Œæˆï¼Œä½†ç»“æœä¸ºç©º')

                    except Exception as e:
                        print(f"âœ— æŠ€æœ¯å› å­æ„å»ºå¤±è´¥: {e}")
                        self.update_session_progress(session_id, 'factor_building', progress_percent + 20,
                                                f'æŠ€æœ¯å› å­æ„å»ºå¤±è´¥: {str(e)[:50]}...')

                elif factor_type == 'statistical':
                    # æ„å»ºç»Ÿè®¡å› å­
                    self.update_session_progress(session_id, 'factor_building', progress_percent, f'æ­£åœ¨æ„å»ºç»Ÿè®¡å› å­...')

                    statistical_builder = self.get_statistical_factor_builder()

                    try:
                        if hasattr(statistical_builder, 'calculate_all_factors'):
                            statistical_df = statistical_builder.calculate_all_factors(data_result['data'])
                        else:
                            statistical_df = statistical_builder.build_all_factors(data_result['data'])

                        if not statistical_df.empty:
                            all_factors = pd.concat([all_factors, statistical_df], axis=1)
                            print(f"âœ“ æˆåŠŸæ„å»ºç»Ÿè®¡å› å­: {len(statistical_df.columns)} ä¸ª")
                            self.update_session_progress(session_id, 'factor_building', progress_percent + 20,
                                                    f'ç»Ÿè®¡å› å­æ„å»ºå®Œæˆ: {len(statistical_df.columns)} ä¸ª')
                        else:
                            print("âœ— ç»Ÿè®¡å› å­æ„å»ºå®Œæˆï¼Œä½†ç»“æœä¸ºç©º")
                            self.update_session_progress(session_id, 'factor_building', progress_percent + 20,
                                                    'ç»Ÿè®¡å› å­æ„å»ºå®Œæˆï¼Œä½†ç»“æœä¸ºç©º')

                    except Exception as e:
                        print(f"âœ— ç»Ÿè®¡å› å­æ„å»ºå¤±è´¥: {e}")
                        self.update_session_progress(session_id, 'factor_building', progress_percent + 20,
                                                f'ç»Ÿè®¡å› å­æ„å»ºå¤±è´¥: {str(e)[:50]}...')

                elif factor_type == 'advanced':
                    # æ„å»ºé«˜çº§å› å­
                    self.update_session_progress(session_id, 'factor_building', progress_percent, f'æ­£åœ¨æ„å»ºé«˜çº§å› å­...')

                    advanced_builder = self.get_advanced_factor_builder()

                    try:
                        if hasattr(advanced_builder, 'calculate_all_factors'):
                            advanced_factors = advanced_builder.calculate_all_factors(data_result['data'])
                        else:
                            advanced_factors = advanced_builder.build_all_factors(data_result['data'])

                        if not advanced_factors.empty:
                            all_factors = pd.concat([all_factors, advanced_factors], axis=1)
                            print(f"âœ“ æˆåŠŸæ„å»ºé«˜çº§å› å­: {len(advanced_factors.columns)} ä¸ª")
                            self.update_session_progress(session_id, 'factor_building', progress_percent + 20,
                                                    f'é«˜çº§å› å­æ„å»ºå®Œæˆ: {len(advanced_factors.columns)} ä¸ª')
                        else:
                            print("âœ— é«˜çº§å› å­æ„å»ºå®Œæˆï¼Œä½†ç»“æœä¸ºç©º")
                            self.update_session_progress(session_id, 'factor_building', progress_percent + 20,
                                                    'é«˜çº§å› å­æ„å»ºå®Œæˆï¼Œä½†ç»“æœä¸ºç©º')

                    except Exception as e:
                        print(f"âœ— é«˜çº§å› å­æ„å»ºå¤±è´¥: {e}")
                        self.update_session_progress(session_id, 'factor_building', progress_percent + 20,
                                                f'é«˜çº§å› å­æ„å»ºå¤±è´¥: {str(e)[:50]}...')

                else:
                    # å…¶ä»–å› å­ç±»å‹
                    self.update_session_progress(session_id, 'factor_building', progress_percent,
                                            f'æ­£åœ¨æ„å»º{factor_type_name}...')

            except Exception as e:
                print(f"âœ— {factor_type_name}æ„å»ºå¤±è´¥: {e}")
                self.update_session_progress(session_id, 'factor_building', progress_percent,
                                        f'{factor_type_name}æ„å»ºå¤±è´¥: {str(e)[:50]}...')

        # å¦‚æœå› å­æ„å»ºæˆåŠŸï¼Œä½¿ç”¨æ„å»ºç»“æœï¼›å¦åˆ™ä½¿ç”¨åŸæœ‰API
        if not all_factors.empty:
            # ä½¿ç”¨çœŸå®æ„å»ºçš„å› å­
            factors_result = {
                'success': True,
                'factors': all_factors,
                'info': {
                    'total_factors': len(all_factors.columns),
                    'factor_names': list(all_factors.columns),
                    'factor_types': factor_types
                }
            }
        else:
            # ä½¿ç”¨åŸæœ‰APIæ„å»ºå› å­
            factors_result = api.build_factors(
                data_result['data'],
                params['factor_types'],
                mining_config
            )

        if not factors_result['success']:
            raise Exception(f"å› å­æ„å»ºå¤±è´¥: {factors_result['error']}")

        # æ•°æ®æ¸…ç†å’Œç´¢å¼•å¯¹é½
        print(f"å¼€å§‹æ¸…ç†å› å­æ•°æ®...")
        factors_df = factors_result['factors']
        print(f"åŸå§‹å› å­å½¢çŠ¶: {factors_df.shape}")
        print(f"åŸå§‹å› å­ç´¢å¼•èŒƒå›´: {factors_df.index.min()} åˆ° {factors_df.index.max()}")
        print(f"åŸå§‹å› å­ç´¢å¼•ç±»å‹: {type(factors_df.index)}")

        # æ£€æŸ¥å¹¶å¤„ç†é‡å¤ç´¢å¼•
        if factors_df.index.duplicated().any():
            print(f"å‘ç°é‡å¤ç´¢å¼•ï¼Œå¼€å§‹æ¸…ç†...")
            duplicate_count = factors_df.index.duplicated().sum()
            print(f"é‡å¤ç´¢å¼•æ•°é‡: {duplicate_count}")

            # ä¿ç•™æœ€åä¸€ä¸ªé‡å¤å€¼
            factors_df = factors_df[~factors_df.index.duplicated(keep='last')]
            print(f"æ¸…ç†åå› å­å½¢çŠ¶: {factors_df.shape}")

        # ç¡®ä¿ç´¢å¼•æ˜¯datetimeç±»å‹
        if not isinstance(factors_df.index, pd.DatetimeIndex):
            print(f"è½¬æ¢ç´¢å¼•ä¸ºdatetimeç±»å‹...")
            factors_df.index = pd.to_datetime(factors_df.index)

        # ä¸å¸‚åœºæ•°æ®å¯¹é½
        market_data = data_result['data']
        print(f"å¸‚åœºæ•°æ®å½¢çŠ¶: {market_data.shape}")
        print(f"å¸‚åœºæ•°æ®ç´¢å¼•èŒƒå›´: {market_data.index.min()} åˆ° {market_data.index.max()}")

        # æ‰¾åˆ°å…±åŒçš„ç´¢å¼•
        common_index = factors_df.index.intersection(market_data.index)
        print(f"å…±åŒç´¢å¼•æ•°é‡: {len(common_index)}")

        if len(common_index) < 100:
            raise Exception(f"å› å­æ•°æ®ä¸å¸‚åœºæ•°æ®å¯¹é½åæ ·æœ¬å¤ªå°‘: {len(common_index)} < 100")

        # å¯¹é½æ•°æ®
        factors_df_aligned = factors_df.loc[common_index]
        market_data_aligned = market_data.loc[common_index]

        print(f"å¯¹é½åå› å­å½¢çŠ¶: {factors_df_aligned.shape}")
        print(f"å¯¹é½åå¸‚åœºæ•°æ®å½¢çŠ¶: {market_data_aligned.shape}")

        # æ£€æŸ¥æ•°æ®è´¨é‡
        print(f"å› å­ç¼ºå¤±å€¼ç»Ÿè®¡:")
        for col in factors_df_aligned.columns:
            missing_count = factors_df_aligned[col].isna().sum()
            missing_ratio = missing_count / len(factors_df_aligned)
            print(f"  {col}: {missing_count} ({missing_ratio:.2%})")

        # å¡«å……ç¼ºå¤±å€¼ï¼ˆä½¿ç”¨å‰å‘å¡«å……ï¼‰
        factors_df_aligned = factors_df_aligned.fillna(method='ffill').fillna(0)
        print(f"ç¼ºå¤±å€¼å¡«å……å®Œæˆ")

        # æ›´æ–°æ•°æ®ç»“æœ
        data_result['data'] = market_data_aligned
        factors_result['factors'] = factors_df_aligned

        self.update_session_progress(session_id, 'factor_building', 100,
                                f'å› å­æ„å»ºå®Œæˆï¼Œå…±{factors_df_aligned.shape[1]}ä¸ªå› å­')

        """æ‰§è¡Œå› å­è¯„ä¼°ï¼ˆåŒåŸæ­¥éª¤3é€»è¾‘ï¼‰"""
        # ... å®ç°ç»†èŠ‚åŒåŸ run_mining_background ä¸­çš„ factor_evaluation æ­¥éª¤ ...
        step_start_time = time.time()
        self.mining_sessions[session_id]['progress_info']['factor_evaluation']['start_time'] = step_start_time
        self.mining_sessions[session_id]['progress_info']['factor_evaluation']['current_step_start'] = step_start_time

        self.update_session_progress(session_id, 'factor_evaluation', 0, 'å¼€å§‹è¯„ä¼°å› å­...')

        # å¼€å§‹å› å­è¯„ä¼°
        self.update_session_progress(session_id, 'factor_evaluation', 10, 'æ­£åœ¨è¯„ä¼°å› å­...')

        # æ‰§è¡ŒçœŸå®çš„å› å­è¯„ä¼°ï¼ˆä¼ å…¥å‰ç«¯å¯è§†åŒ–çš„è¿›åº¦å›è°ƒï¼‰
        evaluation_result = api.evaluate_factors(
            factors_result['factors'],
            data_result['data'],
            mining_config
        )
        # åŸºäºæœ€å°é˜ˆå€¼ç­›é€‰ï¼ˆåªä¿ç•™ç¬¦åˆ min_ic/min_ir çš„å› å­ï¼‰
        try:
            min_ic = float(mining_config.get('min_ic', 0)) if isinstance(mining_config, dict) else 0.0
            min_ir = float(mining_config.get('min_ir', 0)) if isinstance(mining_config, dict) else 0.0
            eval_map = evaluation_result.get('evaluation', {}) or {}

            def pass_thresholds(res: dict) -> bool:
                if not isinstance(res, dict):
                    return False
                ic_candidates = [res.get('ic_pearson'), res.get('ic_spearman')]
                ic_values = [abs(v) for v in ic_candidates if isinstance(v, (int, float))]
                ic_ok = (max(ic_values) if ic_values else 0.0) >= min_ic
                ir_value = res.get('ic_ir')
                if not isinstance(ir_value, (int, float)):
                    ir_value = res.get('sharpe_ratio') if isinstance(res.get('sharpe_ratio'), (int, float)) else 0.0
                ir_ok = ir_value >= min_ir
                return ic_ok and ir_ok

            selected_names = [name for name, res in eval_map.items() if pass_thresholds(res)]
            if selected_names:
                # è¿‡æ»¤å› å­ä¸è¯„ä¼°æ˜ å°„
                factors_result['factors'] = factors_result['factors'][selected_names]
                if 'info' in factors_result:
                    factors_result['info']['factor_names'] = selected_names
                    factors_result['info']['total_factors'] = len(selected_names)
                evaluation_result['evaluation'] = {k: eval_map[k] for k in selected_names}
                print(f"ç­›é€‰åä¿ç•™å› å­æ•°é‡: {len(selected_names)} (min_ic={min_ic}, min_ir={min_ir})")
            else:
                print(f"ç­›é€‰ç»“æœä¸ºç©ºï¼Œä¿ç•™å…¨éƒ¨å› å­ (min_ic={min_ic}, min_ir={min_ir})")
        except Exception as e:
            print(f"ç­›é€‰å› å­å¤±è´¥: {e}")

        if not evaluation_result['success']:
            raise Exception(f"å› å­è¯„ä¼°å¤±è´¥: {evaluation_result['error']}")

        self.update_session_progress(session_id, 'factor_evaluation', 100, 'å› å­è¯„ä¼°å®Œæˆ')

        # å°†è¯„ä¼°ç»“æœå­˜å‚¨åˆ°V3ç³»ç»Ÿ
        try:
            self.update_session_progress(session_id, 'factor_evaluation', 95, 'æ­£åœ¨ä¿å­˜è¯„ä¼°ç»“æœåˆ°V3ç³»ç»Ÿ...')
            api.save_evaluation_results_to_v3(
                factors_result['factors'],
                evaluation_result['evaluation'],
                mining_config
            )
            self.update_session_progress(session_id, 'factor_evaluation', 100, 'è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°V3ç³»ç»Ÿ')
        except Exception as e:
            print(f"ä¿å­˜è¯„ä¼°ç»“æœåˆ°V3ç³»ç»Ÿå¤±è´¥: {e}")
            # ä¸å½±å“ä¸»æµç¨‹ï¼Œç»§ç»­æ‰§è¡Œ

        """æ‰§è¡Œå› å­ä¼˜åŒ–ï¼ˆåŒåŸæ­¥éª¤4é€»è¾‘ï¼‰"""
        # ... å®ç°ç»†èŠ‚åŒåŸ run_mining_background ä¸­çš„ factor_optimization æ­¥éª¤ ...
        step_start_time = time.time()
        self.mining_sessions[session_id]['progress_info']['factor_optimization']['start_time'] = step_start_time
        self.mining_sessions[session_id]['progress_info']['factor_optimization']['current_step_start'] = step_start_time

        self.update_session_progress(session_id, 'factor_optimization', 0, 'å¼€å§‹ä¼˜åŒ–å› å­...')

        # å¼€å§‹å› å­ä¼˜åŒ–
        self.update_session_progress(session_id, 'factor_optimization', 10, 'æ­£åœ¨ä¼˜åŒ–å› å­...')

        # æ‰§è¡ŒçœŸå®çš„å› å­ä¼˜åŒ–
        optimization_result = api.optimize_factor_combination(
            factors_result['factors'],
            data_result['data'],
            mining_config
        )

        if not optimization_result['success']:
            raise Exception(f"å› å­ä¼˜åŒ–å¤±è´¥: {optimization_result['error']}")

        self.update_session_progress(session_id, 'factor_optimization', 100, 'å› å­ä¼˜åŒ–å®Œæˆ')


        """æ‰§è¡Œç»“æœä¿å­˜ï¼ˆåŒåŸæ­¥éª¤5é€»è¾‘ï¼‰"""
        # ... å®ç°ç»†èŠ‚åŒåŸ run_mining_background ä¸­çš„ result_saving æ­¥éª¤ ...
        step_start_time = time.time()
        self.mining_sessions[session_id]['progress_info']['result_saving']['start_time'] = step_start_time
        self.mining_sessions[session_id]['progress_info']['result_saving']['current_step_start'] = step_start_time

        self.update_session_progress(session_id, 'result_saving', 0, 'å¼€å§‹ä¿å­˜ç»“æœ...')

        # ä¿å­˜ç»“æœ
        results = {
            'success': True,
            'session_id': session_id,
            'data_info': data_result.get('info', {}),
            'factors_info': factors_result.get('info', {}),
            'evaluation': evaluation_result.get('evaluation', {}),
            'optimization': optimization_result,
            'output_path': '',
            'report': f"æŒ–æ˜å®Œæˆï¼Œå…±ç”Ÿæˆ {factors_result.get('info', {}).get('total_factors', 0)} ä¸ªå› å­"
        }

        # ä¿å­˜å› å­å®šä¹‰åˆ°factorlib/definitionsæ–‡ä»¶å¤¹
        try:
            print(f"å¼€å§‹ä¿å­˜å› å­å®šä¹‰åˆ°factorlib/definitions...")
            from factor_miner.core.factor_builder import FactorBuilder
            factor_builder = FactorBuilder()

            # æ„å»ºå› å­æ•°æ®å­—å…¸ï¼Œæ ¼å¼ä¸åŸæ¥çš„_save_factors_to_storageæ–¹æ³•ä¸€è‡´
            built_factors = {}
            for factor_type in params.get('factor_types', []):
                if factor_type == 'ml' and 'ml_factors' in locals():
                    built_factors['ml'] = {col: ml_factors[col] for col in ml_factors.columns}
                elif factor_type == 'technical' and 'technical_factors' in locals():
                    built_factors['technical'] = {col: technical_factors[col] for col in technical_factors.columns}
                elif factor_type == 'statistical' and 'statistical_df' in locals():
                    built_factors['statistical'] = {col: statistical_df[col] for col in statistical_df.columns}
                elif factor_type == 'advanced' and 'advanced_factors' in locals():
                    built_factors['advanced'] = {col: advanced_factors[col] for col in advanced_factors.columns}

            # è°ƒç”¨ä¿å­˜æ–¹æ³•
            if built_factors:
                factor_builder._save_factors_to_storage(built_factors, data_result['data'])
                print(f"å› å­å®šä¹‰ä¿å­˜æˆåŠŸåˆ°factorlib/definitions")
            else:
                print(f"æ²¡æœ‰æ‰¾åˆ°å¯ä¿å­˜çš„å› å­æ•°æ®")
        except Exception as e:
            print(f"ä¿å­˜å› å­å®šä¹‰å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

        # ä¿å­˜åˆ°æ–‡ä»¶
        try:
            print(f"å¼€å§‹ä¿å­˜æŒ–æ˜ç»“æœåˆ°æ–‡ä»¶...")
            output_path = self.save_mining_results(session_id, results, params)
            results['output_path'] = str(output_path)
            print(f"æŒ–æ˜ç»“æœä¿å­˜æˆåŠŸ: {output_path}")
        except Exception as e:
            print(f"ä¿å­˜ç»“æœå¤±è´¥: {e}")  # ä½¿ç”¨printè€Œä¸æ˜¯logger
            import traceback
            traceback.print_exc()

        self.update_session_progress(session_id, 'result_saving', 100, 'ç»“æœä¿å­˜å®Œæˆ')

    # --- è¾…åŠ©æ–¹æ³•ï¼ˆåŸè·¯ç”±ä¸­çš„æŸ¥è¯¢æ¥å£é€»è¾‘ï¼‰---
    def get_mining_status(self, session_id: str) -> Dict:
        """è·å–æŒ–æ˜çŠ¶æ€ï¼ˆåŸ get_mining_status è·¯ç”±é€»è¾‘ï¼‰"""
        if session_id not in self.mining_sessions:
            return {'success': False, 'error': 'æŒ–æ˜ä¼šè¯ä¸å­˜åœ¨'}
        session = self.mining_sessions[session_id]
        time_info = self._calculate_time_info(session)
        return {
            'success': True,
            'session_id': session_id,
            'status': session['status'],
            'progress': session['progress'],
            'current_step': session['current_step'],
            'messages': session.get('messages', []),
            'start_time': session['start_time'],
            'end_time': session.get('end_time'),
            'error': session.get('error'),
            'time_info': time_info,
            'progress_info': session.get('progress_info', {}),
            'system_info': session.get('system_info', {})
        }

    def _calculate_time_info(self, session: Dict) -> Dict:
        """è®¡ç®—æ—¶é—´ä¿¡æ¯ï¼ˆåŒåŸ calculate_time_info å‡½æ•°é€»è¾‘ï¼‰"""
        # ... å®ç°ç»†èŠ‚åŒåŸ calculate_time_info å‡½æ•° ...
        try:
            current_time = time.time()
            start_time = datetime.fromisoformat(session['start_time']).timestamp()
            elapsed_time = current_time - start_time

            # è·å–å½“å‰æ­¥éª¤ä¿¡æ¯
            current_step = session.get('current_step', 'data_loading')
            progress_info = session.get('progress_info', {})

            if current_step not in progress_info:
                return {
                    'elapsed_time': round(elapsed_time, 1),
                    'estimated_remaining': 0,
                    'estimated_total': session.get('total_estimated_time', 0),
                    'current_step_progress': 0,
                    'current_step_elapsed': 0,
                    'current_step_remaining': 0
                }

            current_step_info = progress_info[current_step]
            current_step_start = current_step_info.get('current_step_start')

            if current_step_start:
                current_step_elapsed = current_time - current_step_start
                current_step_estimated = current_step_info.get('estimated_time', 10)

                # è®¡ç®—å½“å‰æ­¥éª¤çš„å‰©ä½™æ—¶é—´
                if current_step_elapsed < current_step_estimated:
                    current_step_remaining = current_step_estimated - current_step_elapsed
                else:
                    current_step_remaining = 0

                # è®¡ç®—æ€»ä½“å‰©ä½™æ—¶é—´
                total_estimated = session.get('total_estimated_time', 0)
                if total_estimated > elapsed_time:
                    estimated_remaining = total_estimated - elapsed_time
                else:
                    estimated_remaining = 0

                return {
                    'elapsed_time': round(elapsed_time, 1),
                    'estimated_remaining': round(estimated_remaining, 1),
                    'estimated_total': total_estimated,
                    'current_step_progress': session['progress'].get(current_step, 0),
                    'current_step_elapsed': round(current_step_elapsed, 1),
                    'current_step_remaining': round(current_step_remaining, 1),
                    'current_step_estimated': current_step_estimated
                }
            else:
                return {
                    'elapsed_time': round(elapsed_time, 1),
                    'estimated_remaining': session.get('total_estimated_time', 0),
                    'estimated_total': session.get('total_estimated_time', 0),
                    'current_step_progress': 0,
                    'current_step_elapsed': 0,
                    'current_step_remaining': 0
                }

        except Exception as e:
            print(f"è®¡ç®—æ—¶é—´ä¿¡æ¯å¤±è´¥: {e}")
            return {
                'elapsed_time': 0,
                'estimated_remaining': 0,
                'estimated_total': 0,
                'current_step_progress': 0,
                'current_step_elapsed': 0,
                'current_step_remaining': 0
            }

    # ... å…¶ä»–è¾…åŠ©æ–¹æ³•ï¼ˆå¦‚ get_mining_progressã€get_mining_diff ç­‰ï¼‰...
    def get_mining_progress(self, session_id: str) -> Dict:
        if session_id not in self.mining_sessions:
            return {
                'success': False,
                'error': 'æŒ–æ˜ä¼šè¯ä¸å­˜åœ¨'
            }

        def generate_progress():
            session = self.mining_sessions[session_id]
            last_progress = None
            last_time_info = None
            last_sub_progress = None

            while session['status'] in ['pending', 'running']:
                current_progress = session['progress']
                current_time_info = self._calculate_time_info(session)
                current_sub_progress = session.get('progress_info', {}).get('sub_progress', {})

                # æ£€æŸ¥è¿›åº¦æˆ–æ—¶é—´ä¿¡æ¯æ˜¯å¦æœ‰å˜åŒ–
                progress_changed = current_progress != last_progress
                time_changed = current_time_info != last_time_info
                sub_changed = current_sub_progress != last_sub_progress

                if progress_changed or time_changed or sub_changed:
                    data = {
                        'session_id': session_id,
                        'status': session['status'],
                        'progress': current_progress,
                        'current_step': session['current_step'],
                        'messages': session.get('messages', []),
                        'time_info': current_time_info,
                        'progress_info': session.get('progress_info', {}),
                        'system_info': session.get('system_info', {})
                    }
                    # ç¡®ä¿sub_progresså’Œsub_messagesç»“æ„å­˜åœ¨ï¼Œä½†ä¸å¼ºåˆ¶å›å¡«ä¸»è¿›åº¦
                    try:
                        pi = data.setdefault('progress_info', {})
                        pi.setdefault('sub_progress', {})
                        pi.setdefault('sub_messages', {})
                    except Exception:
                        pass

                    yield f"data: {json.dumps(data)}\n\n"
                    last_progress = current_progress.copy()
                    last_time_info = current_time_info.copy()
                    last_sub_progress = current_sub_progress.copy() if isinstance(current_sub_progress,
                                                                                  dict) else current_sub_progress

                time.sleep(0.5)  # æ›´é¢‘ç¹çš„æ›´æ–°ï¼ˆæ¯0.5ç§’ï¼‰

            # å‘é€æœ€ç»ˆçŠ¶æ€
            final_data = {
                'session_id': session_id,
                'status': session['status'],
                'progress': session['progress'],
                'current_step': session['current_step'],
                'messages': session.get('messages', []),
                'results': session.get('results'),
                'error': session.get('error'),
                'time_info': self._calculate_time_info(session),
                'progress_info': session.get('progress_info', {}),
                'system_info': session.get('system_info', {})
            }

            return final_data

    def update_session_progress(self,session_id, step, progress, message):
        """æ›´æ–°ä¼šè¯è¿›åº¦"""
        if session_id in self.mining_sessions:
            session = self.mining_sessions[session_id]
            session['progress'][step] = progress
            session['current_step'] = step

            if message:
                session['messages'].append({
                    'timestamp': datetime.now().isoformat(),
                    'step': step,
                    'message': message,
                    'progress': progress
                })

            # é™åˆ¶æ¶ˆæ¯æ•°é‡
            if len(session['messages']) > 100:
                session['messages'] = session['messages'][-100:]

            # åˆå§‹åŒ–å­è¿›åº¦ç»“æ„ï¼Œä½†ä¸å¼ºåˆ¶åŒæ­¥ä¸»è¿›åº¦åˆ°å­è¿›åº¦
            try:
                if step == 'factor_building':
                    pi = session.setdefault('progress_info', {})
                    sp = pi.setdefault('sub_progress', {})
                    # ä»…åœ¨å­è¿›åº¦æœªåˆå§‹åŒ–æ—¶è®¾ç½®ä¸º0ï¼Œä¸å¼ºåˆ¶åŒæ­¥ä¸»è¿›åº¦
                    sp.setdefault('ml', 0)
            except Exception:
                pass

            # æ·»åŠ è°ƒè¯•æ—¥å¿—
            print(f"ä¼šè¯ {session_id} æ­¥éª¤ {step} è¿›åº¦: {progress}% - {message}")

    def get_data_info(self, symbol, timeframe, start_date, end_date):
        """è·å–æ•°æ®ä¿¡æ¯ç”¨äºè¿›åº¦ä¼°ç®—"""
        try:
            # æ„å»ºæ•°æ®æ–‡ä»¶è·¯å¾„
            data_dir = Path("data/binance/futures")
            if not data_dir.exists():
                return {'data_size_mb': 100, 'record_count': 1000}  # é»˜è®¤å€¼

            # æŸ¥æ‰¾å¯¹åº”çš„æ•°æ®æ–‡ä»¶
            data_file = data_dir / f"{symbol}_USDT_USDT-{timeframe}-futures.feather"
            if data_file.exists():
                # è·å–æ–‡ä»¶å¤§å°
                file_size = data_file.stat().st_size
                data_size_mb = file_size / (1024 * 1024)

                # ä¼°ç®—è®°å½•æ•°ï¼ˆåŸºäºæ–‡ä»¶å¤§å°ï¼‰
                record_count = int(data_size_mb * 100)  # ç²—ç•¥ä¼°ç®—

                return {
                    'data_size_mb': round(data_size_mb, 2),
                    'record_count': record_count,
                    'file_path': str(data_file)
                }
            else:
                return {'data_size_mb': 100, 'record_count': 1000}  # é»˜è®¤å€¼

        except Exception as e:
            print(f"è·å–æ•°æ®ä¿¡æ¯å¤±è´¥: {e}")
            return {'data_size_mb': 100, 'record_count': 1000}  # é»˜è®¤å€¼

    def save_mining_results(self, session_id, results, config):
        """ä¿å­˜æŒ–æ˜ç»“æœ"""
        try:
            print(f"ä¿å­˜æŒ–æ˜ç»“æœ: session_id={session_id}")
            print(f"ç»“æœç»“æ„: {list(results.keys())}")
            print(f"é…ç½®ç»“æ„: {list(config.keys())}")

            # åˆ›å»ºç»“æœç›®å½•
            results_dir = Path(__file__).parent.parent.parent / "factorlib" / "mining_history"
            # results_dir = Path("factorlib") / "mining_history"
            results_dir.mkdir(parents=True, exist_ok=True)
            print(f"ç»“æœç›®å½•: {results_dir}")

            # ä¿å­˜ç»“æœæ–‡ä»¶
            output_path = results_dir / f"mining_results_{session_id}.json"
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False, default=str)
            print(f"ç»“æœæ–‡ä»¶ä¿å­˜: {output_path}")

            # ä¿å­˜å› å­æ•°æ®ä¸ºCSV
            if 'evaluation' in results and results['evaluation']:
                csv_path = results_dir / f"factors_{session_id}.csv"
                factors_df = pd.DataFrame(results['evaluation'])
                factors_df.to_csv(csv_path, index=False)
                print(f"å› å­CSVä¿å­˜: {csv_path}")
            else:
                print(f"æ²¡æœ‰è¯„ä¼°ç»“æœï¼Œè·³è¿‡CSVä¿å­˜")

            # åŒæ—¶ä¿å­˜åˆ°ä¼šè¯å†å²æ–‡ä»¶
            try:
                print(f"å¼€å§‹ä¿å­˜ä¼šè¯å†å²...")
                self.save_session_to_history(session_id, results, config)
                print(f"ä¼šè¯å†å²ä¿å­˜æˆåŠŸ")
            except Exception as e:
                print(f"ä¿å­˜ä¼šè¯å†å²å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()

            return output_path

        except Exception as e:
            print(f"ä¿å­˜æŒ–æ˜ç»“æœå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise

    def save_session_to_history(self, session_id, results, config):
        """ä¿å­˜ä¼šè¯åˆ°å†å²æ–‡ä»¶"""
        try:
            print(f"ä¿å­˜ä¼šè¯å†å²: session_id={session_id}")

            # åˆ›å»ºå†å²ç›®å½•
            history_dir = Path(__file__).parent.parent.parent / "factorlib" / "mining_history"
            # history_dir = Path("factorlib") / "mining_history"
            history_dir.mkdir(parents=True, exist_ok=True)
            print(f"å†å²ç›®å½•: {history_dir}")

            # å†å²æ–‡ä»¶è·¯å¾„
            history_file = history_dir / "mining_sessions.json"
            print(f"å†å²æ–‡ä»¶: {history_file}")

            # è¯»å–ç°æœ‰å†å²
            if history_file.exists():
                with open(history_file, 'r', encoding='utf-8') as f:
                    history_data = json.load(f)
                print(f"è¯»å–ç°æœ‰å†å²: {len(history_data.get('mining_sessions', []))} ä¸ªä¼šè¯")
            else:
                history_data = {"mining_sessions": [],
                                "metadata": {"total_sessions": 0, "last_updated": "", "version": "1.0"}}
                print(f"åˆ›å»ºæ–°çš„å†å²æ•°æ®ç»“æ„")

            # åˆ›å»ºæ–°çš„ä¼šè¯è®°å½•
            session_record = {
                "session_id": session_id,
                "timestamp": datetime.now().isoformat(),
                "status": "completed",
                "config": {
                    "symbols": config.get('symbols', []),
                    "timeframes": config.get('timeframes', []),
                    "factor_types": config.get('factor_types', []),
                    "max_factors": config.get('max_factors', 15),
                    "optimization_method": config.get('optimization_method', 'greedy'),
                    "start_date": config.get('start_date', ''),
                    "end_date": config.get('end_date', '')
                },
                "results": {
                    "total_factors": results.get('factors_info', {}).get('total_factors', 0),
                    "selected_factors": results.get('optimization', {}).get('selected_factors', []),
                    "optimization_score": results.get('optimization', {}).get('score', 0),
                    "execution_time": 0,  # å¯ä»¥æ·»åŠ å®é™…æ‰§è¡Œæ—¶é—´
                    "output_path": str(results.get('output_path', ''))
                }
            }

            print(f"ä¼šè¯è®°å½•: {session_record}")

            # æ·»åŠ åˆ°å†å²åˆ—è¡¨
            history_data["mining_sessions"].append(session_record)

            # æ›´æ–°å…ƒæ•°æ®
            history_data["metadata"]["total_sessions"] = len(history_data["mining_sessions"])
            history_data["metadata"]["last_updated"] = datetime.now().isoformat()

            # ä¿å­˜å†å²æ–‡ä»¶
            with open(history_file, 'w', encoding='utf-8') as f:
                json.dump(history_data, f, indent=2, ensure_ascii=False, default=str)

            print(f"ä¼šè¯ {session_id} å·²ä¿å­˜åˆ°å†å²æ–‡ä»¶")

        except Exception as e:
            print(f"ä¿å­˜ä¼šè¯å†å²å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise